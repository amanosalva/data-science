{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-12-06T17:32:59+01:00\n",
      "\n",
      "CPython 3.6.1\n",
      "IPython 6.2.1\n",
      "\n",
      "compiler   : GCC 4.8.2 20140120 (Red Hat 4.8.2-15)\n",
      "system     : Linux\n",
      "release    : 4.10.0-40-generic\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 8\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = [10, 10]\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimización de hiperparámetros\n",
    "\n",
    "Hasta ahora hemos visto una manera relativamente sencilla de ver que valores de los hiperparámetros funcionan mejor, mediante las curvas de validación.\n",
    "\n",
    "Estas curvas son muy útiles para darnos información a los Data Scientists, pero tienen dos problemas:\n",
    "- Son métodos gráficos, esto significa que necesitan un humano para interpretarlas y no nos permiten automatizar el proceso para encontrar los hiperparámetros óptimos.\n",
    "- Solo toman un hiperparámetro a la vez. Esto significa que hacen que sea más dificil el evaluar combinaciones de los hiperparámetros (si quisieramos evaluar multiples hiperparámetros tendriamos que hacer gráficas de planos o hiperplanos).\n",
    "\n",
    "Vamos a ver ahora métodos más robustos para dado un modelo, encontrar el conjunto de hiperparámetros que hace que funcione mejor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargamos los datos\n",
    "\n",
    "Vamos a usar un dataset nuevo, el [Census Income Dataset](https://archive.ics.uci.edu/ml/datasets/Census+Income). Es un dataset que tiene datos demográficos sobre 50,000 personas en Estados Unidos y como variable objetivo tiene una variable booleana (Verdadero/Falso) sobre si dicha persona gana más de 50K$ al año o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "censo = pd.read_csv(\"data/salario_censo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "censo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edad</th>\n",
       "      <th>clase_laboral</th>\n",
       "      <th>nivel_educativo</th>\n",
       "      <th>status_matrimonial</th>\n",
       "      <th>ocupacion</th>\n",
       "      <th>relacion</th>\n",
       "      <th>raza</th>\n",
       "      <th>genero</th>\n",
       "      <th>ganancias_capital</th>\n",
       "      <th>perdidas_capital</th>\n",
       "      <th>horas_laborables</th>\n",
       "      <th>pais_origen</th>\n",
       "      <th>objetivo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   edad      clase_laboral  nivel_educativo   status_matrimonial  \\\n",
       "0    39          State-gov               13        Never-married   \n",
       "1    50   Self-emp-not-inc               13   Married-civ-spouse   \n",
       "2    38            Private                9             Divorced   \n",
       "3    53            Private                7   Married-civ-spouse   \n",
       "4    28            Private               13   Married-civ-spouse   \n",
       "\n",
       "            ocupacion        relacion    raza   genero  ganancias_capital  \\\n",
       "0        Adm-clerical   Not-in-family   White     Male               2174   \n",
       "1     Exec-managerial         Husband   White     Male                  0   \n",
       "2   Handlers-cleaners   Not-in-family   White     Male                  0   \n",
       "3   Handlers-cleaners         Husband   Black     Male                  0   \n",
       "4      Prof-specialty            Wife   Black   Female                  0   \n",
       "\n",
       "   perdidas_capital  horas_laborables     pais_origen objetivo  \n",
       "0                 0                40   United-States    <=50K  \n",
       "1                 0                13   United-States    <=50K  \n",
       "2                 0                40   United-States    <=50K  \n",
       "3                 0                40   United-States    <=50K  \n",
       "4                 0                40            Cuba    <=50K  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "censo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline de procesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "variable_dependiente = \"objetivo\"\n",
    "variables_independientes = censo.drop(variable_dependiente, axis=1).columns\n",
    "censo_X = censo[variables_independientes]\n",
    "censo_y = censo[variable_dependiente]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' <=50K', ' >50K'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "censo_y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso la variable objetivo está definida como texto, asi que la convertimos a una variable binaria numérica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "censo_y = censo_y.replace({\" <=50K\":0, \" >50K\":1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos datos en numéricos y no numéricos. Viendo el [diccionario de datos](https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names) del dataset vemos que no hay variables categóricas, solo la variable educacion que ya viene codificada como numérica (*education-num*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datos_numericos = censo_X.select_dtypes([int, float])\n",
    "col_numericas = datos_numericos.columns\n",
    "\n",
    "datos_categoricos = censo_X.select_dtypes([object])\n",
    "col_no_numericas = datos_categoricos.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a usar un transformador nuevo `MultiLabelBinarizer`. Es como el LabelBinarizer pero funciona para multiples columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer, StandardScaler, MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 0, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 1, 0, 0, 1],\n",
       "       [0, 1, 0, 1, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 1, 0, 1, 0, 0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = MultiLabelBinarizer()\n",
    "b.fit_transform(\n",
    " [\n",
    "     [\"gato\", \"patata\", \"rojo\"],\n",
    "     [\"perro\", \"zanahoria\", \"azul\"],\n",
    "     [\"camello\", \"patata\", \"verde\"],\n",
    "     [\"gato\", \"patata\", \"rojo\"]\n",
    " ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con `classes_` podemos ver los diferentes valores de las variables categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['azul', 'camello', 'gato', 'patata', 'perro', 'rojo', 'verde',\n",
       "       'zanahoria'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el transformador `BinarizadorMultipleCategorico` que es básicamente el MultiLabelBinarizer pero \"arreglado\" para que funcione en Pipelines (Estoy usando sklearn 0.19.0, este bug se arreglará en el futuro)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "from sklearn import preprocessing\n",
    "\n",
    "class ColumnExtractor(TransformerMixin):\n",
    "    \"\"\"Transformador que selecciona columnas de un dataframe\"\"\"\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        \n",
    "    def transform(self, X, **transform_params):\n",
    "        return X[self.columns].as_matrix()\n",
    "        \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "class BinarizadorMultipleCategorico(preprocessing.MultiLabelBinarizer):\n",
    "    def fit(self, X, y=None):\n",
    "        super(BinarizadorMultipleCategorico, self).fit(X)\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        return super(BinarizadorMultipleCategorico, self).transform(X)\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return super(BinarizadorMultipleCategorico, self).fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline_numerico = Pipeline([\n",
    "    ('selector_numerico', ColumnExtractor(columns=col_numericas)),\n",
    "    ('imputador', Imputer()),\n",
    "    ('escalador', StandardScaler()),\n",
    "])\n",
    "\n",
    "pipeline_categorico = Pipeline([\n",
    "    ('selector_categorico', ColumnExtractor(columns=col_no_numericas)),\n",
    "    ('codificador_numerico', BinarizadorMultipleCategorico()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 84)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_categorico.fit_transform(censo_X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['edad', 'nivel_educativo', 'ganancias_capital', 'perdidas_capital',\n",
       "       'horas_laborables'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_numericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_numerico.fit_transform(censo_X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline_procesado = FeatureUnion([\n",
    "    ('transformacion_numericas', pipeline_numerico),\n",
    "    ('transformacion_categorica', pipeline_categorico),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('transformacion_numericas', Pipeline(memory=None,\n",
       "     steps=[('selector_numerico', <__main__.ColumnExtractor object at 0x7f8ddb4420b8>), ('imputador', Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)), ('escalador', StandardScaler(copy=True, with_mean=...28>), ('codificador_numerico', BinarizadorMultipleCategorico(classes=None, sparse_output=False))]))],\n",
       "       transformer_weights=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_procesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "censo_X_procesado = pipeline_procesado.fit_transform(censo_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 89)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "censo_X_procesado.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes que nada vamos a ver que puntuaciones tienen unos cuantos modelos con sus  hiperparámetro por defecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resultados = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def evaluar_modelo(estimador, X, y):\n",
    "    resultados_estimador = cross_validate(estimador, X, y,\n",
    "                     scoring=\"roc_auc\", n_jobs=-1, cv=5, return_train_score=True)\n",
    "    return resultados_estimador\n",
    "\n",
    "def ver_resultados():\n",
    "    resultados_df  = pd.DataFrame(resultados).T\n",
    "    resultados_cols = resultados_df.columns\n",
    "    for col in resultados_df:\n",
    "        resultados_df[col] = resultados_df[col].apply(np.mean)\n",
    "        resultados_df[col+\"_idx\"] = resultados_df[col] / resultados_df[col].max()\n",
    "    return resultados_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resultados[\"reg_logistica\"] = evaluar_modelo(LogisticRegression(), censo_X_procesado, censo_y)\n",
    "resultados[\"naive_bayes\"] = evaluar_modelo(GaussianNB(), censo_X_procesado, censo_y)\n",
    "resultados[\"rf\"] = evaluar_modelo(RandomForestClassifier(), censo_X_procesado, censo_y)\n",
    "resultados[\"svc\"] = evaluar_modelo(SVC(), censo_X_procesado, censo_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "      <th>fit_time_idx</th>\n",
       "      <th>score_time_idx</th>\n",
       "      <th>test_score_idx</th>\n",
       "      <th>train_score_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>naive_bayes</th>\n",
       "      <td>0.061415</td>\n",
       "      <td>0.011542</td>\n",
       "      <td>0.781202</td>\n",
       "      <td>0.783341</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>0.001289</td>\n",
       "      <td>0.859760</td>\n",
       "      <td>0.786943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_logistica</th>\n",
       "      <td>0.394294</td>\n",
       "      <td>0.021813</td>\n",
       "      <td>0.906715</td>\n",
       "      <td>0.908326</td>\n",
       "      <td>0.006094</td>\n",
       "      <td>0.002436</td>\n",
       "      <td>0.997894</td>\n",
       "      <td>0.912503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.389938</td>\n",
       "      <td>0.017129</td>\n",
       "      <td>0.870704</td>\n",
       "      <td>0.995423</td>\n",
       "      <td>0.006027</td>\n",
       "      <td>0.001913</td>\n",
       "      <td>0.958262</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svc</th>\n",
       "      <td>64.697272</td>\n",
       "      <td>8.953962</td>\n",
       "      <td>0.908628</td>\n",
       "      <td>0.910540</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                fit_time  score_time  test_score  train_score  fit_time_idx  \\\n",
       "naive_bayes     0.061415    0.011542    0.781202     0.783341      0.000949   \n",
       "reg_logistica   0.394294    0.021813    0.906715     0.908326      0.006094   \n",
       "rf              0.389938    0.017129    0.870704     0.995423      0.006027   \n",
       "svc            64.697272    8.953962    0.908628     0.910540      1.000000   \n",
       "\n",
       "               score_time_idx  test_score_idx  train_score_idx  \n",
       "naive_bayes          0.001289        0.859760         0.786943  \n",
       "reg_logistica        0.002436        0.997894         0.912503  \n",
       "rf                   0.001913        0.958262         1.000000  \n",
       "svc                  1.000000        1.000000         0.914727  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ver_resultados()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a seleccionar un estimador en función de los resultados iniciales y optimizarlo. Elijo el estimador Random Forest por que funciona muy bien en comparación a los demás y es bastánte rápido de entrenar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimador_rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn tiene dos métodos de optimización de hiperparámetros, [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV) y [RandomizedSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV).\n",
    "\n",
    "`GridSearchCV` funciona realizando una busqueda en una malla, es decir, pasandole un conjunto de posibles opciones de hiperparámetros evalua de forma completa cada combinación de dichos parámetros (es decir, el valor 1 del hiperparámetro 1 combinado con todos los posibles valores de los demás hiperparámetros, el valor 2 del hiperparámetro 1 combinado con todos los posibles valores de los demás hiperparámetros, etcétera).\n",
    "\n",
    "La ventaja de utilizar una búsqueda de malla es que nos aseguramos de que se han probado todas las combinaciones posibles. El problema es que el proceso requiere mucho tiempo de computación, y según que dataset usemos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295 ns ± 15.7 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "import time\n",
    "def foo():\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "869 ns ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1  #n 1 dice que ejecute esta celda solo una vez, -r 1 que ejecute un solo loop\n",
    "def foo():\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A random forest classifier.\n",
      "\n",
      "    A random forest is a meta estimator that fits a number of decision tree\n",
      "    classifiers on various sub-samples of the dataset and use averaging to\n",
      "    improve the predictive accuracy and control over-fitting.\n",
      "    The sub-sample size is always the same as the original\n",
      "    input sample size but the samples are drawn with replacement if\n",
      "    `bootstrap=True` (default).\n",
      "\n",
      "    Read more in the :ref:`User Guide <forest>`.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    n_estimators : integer, optional (default=10)\n",
      "        The number of trees in the forest.\n",
      "\n",
      "    criterion : string, optional (default=\"gini\")\n",
      "        The function to measure the quality of a split. Supported criteria are\n",
      "        \"gini\" for the Gini impurity and \"entropy\" for the information gain.\n",
      "        Note: this parameter is tree-specific.\n",
      "\n",
      "    max_features : int, float, string or None, optional (default=\"auto\")\n",
      "        The number of features to consider when looking for the best split:\n",
      "\n",
      "        - If int, then consider `max_features` features at each split.\n",
      "        - If float, then `max_features` is a percentage and\n",
      "          `int(max_features * n_features)` features are considered at each\n",
      "          split.\n",
      "        - If \"auto\", then `max_features=sqrt(n_features)`.\n",
      "        - If \"sqrt\", then `max_features=sqrt(n_features)` (same as \"auto\").\n",
      "        - If \"log2\", then `max_features=log2(n_features)`.\n",
      "        - If None, then `max_features=n_features`.\n",
      "\n",
      "        Note: the search for a split does not stop until at least one\n",
      "        valid partition of the node samples is found, even if it requires to\n",
      "        effectively inspect more than ``max_features`` features.\n",
      "\n",
      "    max_depth : integer or None, optional (default=None)\n",
      "        The maximum depth of the tree. If None, then nodes are expanded until\n",
      "        all leaves are pure or until all leaves contain less than\n",
      "        min_samples_split samples.\n",
      "\n",
      "    min_samples_split : int, float, optional (default=2)\n",
      "        The minimum number of samples required to split an internal node:\n",
      "\n",
      "        - If int, then consider `min_samples_split` as the minimum number.\n",
      "        - If float, then `min_samples_split` is a percentage and\n",
      "          `ceil(min_samples_split * n_samples)` are the minimum\n",
      "          number of samples for each split.\n",
      "\n",
      "        .. versionchanged:: 0.18\n",
      "           Added float values for percentages.\n",
      "\n",
      "    min_samples_leaf : int, float, optional (default=1)\n",
      "        The minimum number of samples required to be at a leaf node:\n",
      "\n",
      "        - If int, then consider `min_samples_leaf` as the minimum number.\n",
      "        - If float, then `min_samples_leaf` is a percentage and\n",
      "          `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      "          number of samples for each node.\n",
      "\n",
      "        .. versionchanged:: 0.18\n",
      "           Added float values for percentages.\n",
      "\n",
      "    min_weight_fraction_leaf : float, optional (default=0.)\n",
      "        The minimum weighted fraction of the sum total of weights (of all\n",
      "        the input samples) required to be at a leaf node. Samples have\n",
      "        equal weight when sample_weight is not provided.\n",
      "\n",
      "    max_leaf_nodes : int or None, optional (default=None)\n",
      "        Grow trees with ``max_leaf_nodes`` in best-first fashion.\n",
      "        Best nodes are defined as relative reduction in impurity.\n",
      "        If None then unlimited number of leaf nodes.\n",
      "\n",
      "    min_impurity_split : float,\n",
      "        Threshold for early stopping in tree growth. A node will split\n",
      "        if its impurity is above the threshold, otherwise it is a leaf.\n",
      "\n",
      "        .. deprecated:: 0.19\n",
      "           ``min_impurity_split`` has been deprecated in favor of\n",
      "           ``min_impurity_decrease`` in 0.19 and will be removed in 0.21.\n",
      "           Use ``min_impurity_decrease`` instead.\n",
      "\n",
      "    min_impurity_decrease : float, optional (default=0.)\n",
      "        A node will be split if this split induces a decrease of the impurity\n",
      "        greater than or equal to this value.\n",
      "\n",
      "        The weighted impurity decrease equation is the following::\n",
      "\n",
      "            N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      "                                - N_t_L / N_t * left_impurity)\n",
      "\n",
      "        where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      "        samples at the current node, ``N_t_L`` is the number of samples in the\n",
      "        left child, and ``N_t_R`` is the number of samples in the right child.\n",
      "\n",
      "        ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      "        if ``sample_weight`` is passed.\n",
      "\n",
      "        .. versionadded:: 0.19\n",
      "\n",
      "    bootstrap : boolean, optional (default=True)\n",
      "        Whether bootstrap samples are used when building trees.\n",
      "\n",
      "    oob_score : bool (default=False)\n",
      "        Whether to use out-of-bag samples to estimate\n",
      "        the generalization accuracy.\n",
      "\n",
      "    n_jobs : integer, optional (default=1)\n",
      "        The number of jobs to run in parallel for both `fit` and `predict`.\n",
      "        If -1, then the number of jobs is set to the number of cores.\n",
      "\n",
      "    random_state : int, RandomState instance or None, optional (default=None)\n",
      "        If int, random_state is the seed used by the random number generator;\n",
      "        If RandomState instance, random_state is the random number generator;\n",
      "        If None, the random number generator is the RandomState instance used\n",
      "        by `np.random`.\n",
      "\n",
      "    verbose : int, optional (default=0)\n",
      "        Controls the verbosity of the tree building process.\n",
      "\n",
      "    warm_start : bool, optional (default=False)\n",
      "        When set to ``True``, reuse the solution of the previous call to fit\n",
      "        and add more estimators to the ensemble, otherwise, just fit a whole\n",
      "        new forest.\n",
      "\n",
      "    class_weight : dict, list of dicts, \"balanced\",\n",
      "        \"balanced_subsample\" or None, optional (default=None)\n",
      "        Weights associated with classes in the form ``{class_label: weight}``.\n",
      "        If not given, all classes are supposed to have weight one. For\n",
      "        multi-output problems, a list of dicts can be provided in the same\n",
      "        order as the columns of y.\n",
      "\n",
      "        Note that for multioutput (including multilabel) weights should be\n",
      "        defined for each class of every column in its own dict. For example,\n",
      "        for four-class multilabel classification weights should be\n",
      "        [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\n",
      "        [{1:1}, {2:5}, {3:1}, {4:1}].\n",
      "\n",
      "        The \"balanced\" mode uses the values of y to automatically adjust\n",
      "        weights inversely proportional to class frequencies in the input data\n",
      "        as ``n_samples / (n_classes * np.bincount(y))``\n",
      "\n",
      "        The \"balanced_subsample\" mode is the same as \"balanced\" except that\n",
      "        weights are computed based on the bootstrap sample for every tree\n",
      "        grown.\n",
      "\n",
      "        For multi-output, the weights of each column of y will be multiplied.\n",
      "\n",
      "        Note that these weights will be multiplied with sample_weight (passed\n",
      "        through the fit method) if sample_weight is specified.\n",
      "\n",
      "    Attributes\n",
      "    ----------\n",
      "    estimators_ : list of DecisionTreeClassifier\n",
      "        The collection of fitted sub-estimators.\n",
      "\n",
      "    classes_ : array of shape = [n_classes] or a list of such arrays\n",
      "        The classes labels (single output problem), or a list of arrays of\n",
      "        class labels (multi-output problem).\n",
      "\n",
      "    n_classes_ : int or list\n",
      "        The number of classes (single output problem), or a list containing the\n",
      "        number of classes for each output (multi-output problem).\n",
      "\n",
      "    n_features_ : int\n",
      "        The number of features when ``fit`` is performed.\n",
      "\n",
      "    n_outputs_ : int\n",
      "        The number of outputs when ``fit`` is performed.\n",
      "\n",
      "    feature_importances_ : array of shape = [n_features]\n",
      "        The feature importances (the higher, the more important the feature).\n",
      "\n",
      "    oob_score_ : float\n",
      "        Score of the training dataset obtained using an out-of-bag estimate.\n",
      "\n",
      "    oob_decision_function_ : array of shape = [n_samples, n_classes]\n",
      "        Decision function computed with out-of-bag estimate on the training\n",
      "        set. If n_estimators is small it might be possible that a data point\n",
      "        was never left out during the bootstrap. In this case,\n",
      "        `oob_decision_function_` might contain NaN.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> from sklearn.ensemble import RandomForestClassifier\n",
      "    >>> from sklearn.datasets import make_classification\n",
      "    >>>\n",
      "    >>> X, y = make_classification(n_samples=1000, n_features=4,\n",
      "    ...                            n_informative=2, n_redundant=0,\n",
      "    ...                            random_state=0, shuffle=False)\n",
      "    >>> clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
      "    >>> clf.fit(X, y)\n",
      "    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "                min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                min_samples_leaf=1, min_samples_split=2,\n",
      "                min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "                oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
      "    >>> print(clf.feature_importances_)\n",
      "    [ 0.17287856  0.80608704  0.01884792  0.00218648]\n",
      "    >>> print(clf.predict([[0, 0, 0, 0]]))\n",
      "    [1]\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The default values for the parameters controlling the size of the trees\n",
      "    (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
      "    unpruned trees which can potentially be very large on some data sets. To\n",
      "    reduce memory consumption, the complexity and size of the trees should be\n",
      "    controlled by setting those parameter values.\n",
      "\n",
      "    The features are always randomly permuted at each split. Therefore,\n",
      "    the best found split may vary, even with the same training data,\n",
      "    ``max_features=n_features`` and ``bootstrap=False``, if the improvement\n",
      "    of the criterion is identical for several splits enumerated during the\n",
      "    search of the best split. To obtain a deterministic behaviour during\n",
      "    fitting, ``random_state`` has to be fixed.\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "\n",
      "    .. [1] L. Breiman, \"Random Forests\", Machine Learning, 45(1), 5-32, 2001.\n",
      "\n",
      "    See also\n",
      "    --------\n",
      "    DecisionTreeClassifier, ExtraTreesClassifier\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(estimador_rf.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 10,\n",
       " 'n_jobs': 1,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimador_rf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a definir los límites de la búsqueda de hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  10,  120,  230,  340,  450,  560,  670,  780,  890, 1000])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(10,1000,10).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parametros_busqueda_rf = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"n_estimators\": np.linspace(10,1000,10).astype(int),\n",
    "    \"class_weight\": [None, \"balanced\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=estimador_rf, \n",
    "                    param_grid=parametros_busqueda_rf,\n",
    "                    scoring=\"roc_auc\", n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GridSearchCV` se comporta como un estimador en cuanto a que tiene un metodo fit que usamos para \"entrenarlo\" y que realize la búsqueda en malla.\n",
    "\n",
    "Para ver cuanto tiempo tarda en realizar la búsqueda usamos la mágia de Jupyter notebook `%%timeit` que evalua el tiempo que tarda una función en ejecutarse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.5 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "grid.fit(censo_X_procesado, censo_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En mi ordenador la busqueda en malla ha tardado 7minutos y 49 segundos \n",
    "\n",
    "Ahora podemos ver la puntuación que ha obtenido el mejor estimador así como los parámetros del mismo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89726431782\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=890, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras haberlo ajustado, Gridsearch nos devuelve el ranking de todas las variantes evaluadas junto con métricas de su funcionamiento con el atributo `cv_results_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>48.395469</td>\n",
       "      <td>3.825982</td>\n",
       "      <td>0.897264</td>\n",
       "      <td>0.998138</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>890</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.894322</td>\n",
       "      <td>0.998229</td>\n",
       "      <td>0.896448</td>\n",
       "      <td>0.998153</td>\n",
       "      <td>0.901023</td>\n",
       "      <td>0.998032</td>\n",
       "      <td>1.722333</td>\n",
       "      <td>0.315958</td>\n",
       "      <td>0.002796</td>\n",
       "      <td>0.000081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>37.419543</td>\n",
       "      <td>2.961567</td>\n",
       "      <td>0.897248</td>\n",
       "      <td>0.998130</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>670</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.894501</td>\n",
       "      <td>0.998228</td>\n",
       "      <td>0.896451</td>\n",
       "      <td>0.998141</td>\n",
       "      <td>0.900792</td>\n",
       "      <td>0.998021</td>\n",
       "      <td>1.058009</td>\n",
       "      <td>0.130893</td>\n",
       "      <td>0.002629</td>\n",
       "      <td>0.000085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>56.035860</td>\n",
       "      <td>3.788953</td>\n",
       "      <td>0.897244</td>\n",
       "      <td>0.998139</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.894072</td>\n",
       "      <td>0.998229</td>\n",
       "      <td>0.896487</td>\n",
       "      <td>0.998146</td>\n",
       "      <td>0.901173</td>\n",
       "      <td>0.998042</td>\n",
       "      <td>1.453320</td>\n",
       "      <td>0.025295</td>\n",
       "      <td>0.002948</td>\n",
       "      <td>0.000076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>42.341748</td>\n",
       "      <td>3.100389</td>\n",
       "      <td>0.897123</td>\n",
       "      <td>0.998136</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>780</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.894375</td>\n",
       "      <td>0.998222</td>\n",
       "      <td>0.896254</td>\n",
       "      <td>0.998156</td>\n",
       "      <td>0.900739</td>\n",
       "      <td>0.998031</td>\n",
       "      <td>1.235332</td>\n",
       "      <td>0.239111</td>\n",
       "      <td>0.002669</td>\n",
       "      <td>0.000079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>29.182102</td>\n",
       "      <td>2.295158</td>\n",
       "      <td>0.897005</td>\n",
       "      <td>0.998133</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>560</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.894167</td>\n",
       "      <td>0.998228</td>\n",
       "      <td>0.896365</td>\n",
       "      <td>0.998151</td>\n",
       "      <td>0.900484</td>\n",
       "      <td>0.998021</td>\n",
       "      <td>0.463407</td>\n",
       "      <td>0.318522</td>\n",
       "      <td>0.002618</td>\n",
       "      <td>0.000085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>24.451602</td>\n",
       "      <td>1.752896</td>\n",
       "      <td>0.896987</td>\n",
       "      <td>0.998122</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>450</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.894299</td>\n",
       "      <td>0.998227</td>\n",
       "      <td>0.896358</td>\n",
       "      <td>0.998126</td>\n",
       "      <td>0.900303</td>\n",
       "      <td>0.998014</td>\n",
       "      <td>0.518100</td>\n",
       "      <td>0.179451</td>\n",
       "      <td>0.002491</td>\n",
       "      <td>0.000087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>39.529309</td>\n",
       "      <td>3.353667</td>\n",
       "      <td>0.896701</td>\n",
       "      <td>0.998138</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>890</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'n...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.893811</td>\n",
       "      <td>0.998224</td>\n",
       "      <td>0.895982</td>\n",
       "      <td>0.998142</td>\n",
       "      <td>0.900310</td>\n",
       "      <td>0.998048</td>\n",
       "      <td>2.404425</td>\n",
       "      <td>0.397396</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>48.145448</td>\n",
       "      <td>3.716241</td>\n",
       "      <td>0.896669</td>\n",
       "      <td>0.998139</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'n...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.893764</td>\n",
       "      <td>0.998226</td>\n",
       "      <td>0.896117</td>\n",
       "      <td>0.998144</td>\n",
       "      <td>0.900128</td>\n",
       "      <td>0.998045</td>\n",
       "      <td>2.437924</td>\n",
       "      <td>0.189916</td>\n",
       "      <td>0.002627</td>\n",
       "      <td>0.000074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>33.959718</td>\n",
       "      <td>2.785672</td>\n",
       "      <td>0.896637</td>\n",
       "      <td>0.998135</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>780</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'n...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.893648</td>\n",
       "      <td>0.998226</td>\n",
       "      <td>0.895913</td>\n",
       "      <td>0.998130</td>\n",
       "      <td>0.900351</td>\n",
       "      <td>0.998050</td>\n",
       "      <td>0.768166</td>\n",
       "      <td>0.143435</td>\n",
       "      <td>0.002784</td>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>34.654465</td>\n",
       "      <td>2.194206</td>\n",
       "      <td>0.896564</td>\n",
       "      <td>0.997393</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>670</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.894296</td>\n",
       "      <td>0.997597</td>\n",
       "      <td>0.895903</td>\n",
       "      <td>0.997535</td>\n",
       "      <td>0.899494</td>\n",
       "      <td>0.997047</td>\n",
       "      <td>0.568587</td>\n",
       "      <td>0.067388</td>\n",
       "      <td>0.002173</td>\n",
       "      <td>0.000246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.892130</td>\n",
       "      <td>1.183849</td>\n",
       "      <td>0.896536</td>\n",
       "      <td>0.998112</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>340</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'n...</td>\n",
       "      <td>11</td>\n",
       "      <td>0.893929</td>\n",
       "      <td>0.998192</td>\n",
       "      <td>0.895686</td>\n",
       "      <td>0.998135</td>\n",
       "      <td>0.899993</td>\n",
       "      <td>0.998010</td>\n",
       "      <td>0.685280</td>\n",
       "      <td>0.051733</td>\n",
       "      <td>0.002547</td>\n",
       "      <td>0.000076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23.809666</td>\n",
       "      <td>1.845498</td>\n",
       "      <td>0.896509</td>\n",
       "      <td>0.998139</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>560</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'n...</td>\n",
       "      <td>12</td>\n",
       "      <td>0.893609</td>\n",
       "      <td>0.998231</td>\n",
       "      <td>0.895805</td>\n",
       "      <td>0.998149</td>\n",
       "      <td>0.900112</td>\n",
       "      <td>0.998038</td>\n",
       "      <td>0.987909</td>\n",
       "      <td>0.044797</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.000079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.358596</td>\n",
       "      <td>1.488175</td>\n",
       "      <td>0.896504</td>\n",
       "      <td>0.998136</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>450</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'n...</td>\n",
       "      <td>13</td>\n",
       "      <td>0.893830</td>\n",
       "      <td>0.998224</td>\n",
       "      <td>0.895593</td>\n",
       "      <td>0.998149</td>\n",
       "      <td>0.900089</td>\n",
       "      <td>0.998034</td>\n",
       "      <td>0.327186</td>\n",
       "      <td>0.019576</td>\n",
       "      <td>0.002635</td>\n",
       "      <td>0.000078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>29.092304</td>\n",
       "      <td>1.862562</td>\n",
       "      <td>0.896485</td>\n",
       "      <td>0.997386</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>560</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>14</td>\n",
       "      <td>0.894056</td>\n",
       "      <td>0.997584</td>\n",
       "      <td>0.895671</td>\n",
       "      <td>0.997530</td>\n",
       "      <td>0.899728</td>\n",
       "      <td>0.997043</td>\n",
       "      <td>0.817800</td>\n",
       "      <td>0.069652</td>\n",
       "      <td>0.002386</td>\n",
       "      <td>0.000243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>28.230006</td>\n",
       "      <td>2.223272</td>\n",
       "      <td>0.896429</td>\n",
       "      <td>0.998136</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>670</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'n...</td>\n",
       "      <td>15</td>\n",
       "      <td>0.893536</td>\n",
       "      <td>0.998230</td>\n",
       "      <td>0.895759</td>\n",
       "      <td>0.998133</td>\n",
       "      <td>0.899993</td>\n",
       "      <td>0.998045</td>\n",
       "      <td>0.818327</td>\n",
       "      <td>0.029125</td>\n",
       "      <td>0.002678</td>\n",
       "      <td>0.000075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>37.938799</td>\n",
       "      <td>1.949409</td>\n",
       "      <td>0.896425</td>\n",
       "      <td>0.997419</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>16</td>\n",
       "      <td>0.893898</td>\n",
       "      <td>0.997612</td>\n",
       "      <td>0.895982</td>\n",
       "      <td>0.997572</td>\n",
       "      <td>0.899396</td>\n",
       "      <td>0.997073</td>\n",
       "      <td>4.150428</td>\n",
       "      <td>0.178393</td>\n",
       "      <td>0.002266</td>\n",
       "      <td>0.000245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>42.238346</td>\n",
       "      <td>2.189633</td>\n",
       "      <td>0.896414</td>\n",
       "      <td>0.997422</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>890</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>17</td>\n",
       "      <td>0.893771</td>\n",
       "      <td>0.997623</td>\n",
       "      <td>0.895836</td>\n",
       "      <td>0.997563</td>\n",
       "      <td>0.899636</td>\n",
       "      <td>0.997079</td>\n",
       "      <td>1.035562</td>\n",
       "      <td>0.334611</td>\n",
       "      <td>0.002429</td>\n",
       "      <td>0.000244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>41.215544</td>\n",
       "      <td>2.439488</td>\n",
       "      <td>0.896400</td>\n",
       "      <td>0.997400</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>780</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>18</td>\n",
       "      <td>0.893884</td>\n",
       "      <td>0.997605</td>\n",
       "      <td>0.895749</td>\n",
       "      <td>0.997551</td>\n",
       "      <td>0.899569</td>\n",
       "      <td>0.997045</td>\n",
       "      <td>1.107557</td>\n",
       "      <td>0.060664</td>\n",
       "      <td>0.002366</td>\n",
       "      <td>0.000252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>17.711762</td>\n",
       "      <td>1.251416</td>\n",
       "      <td>0.896377</td>\n",
       "      <td>0.998095</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>340</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>19</td>\n",
       "      <td>0.893707</td>\n",
       "      <td>0.998202</td>\n",
       "      <td>0.896100</td>\n",
       "      <td>0.998102</td>\n",
       "      <td>0.899324</td>\n",
       "      <td>0.997980</td>\n",
       "      <td>0.519022</td>\n",
       "      <td>0.109759</td>\n",
       "      <td>0.002301</td>\n",
       "      <td>0.000091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>20.523469</td>\n",
       "      <td>1.268593</td>\n",
       "      <td>0.896254</td>\n",
       "      <td>0.997353</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>340</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.893587</td>\n",
       "      <td>0.997567</td>\n",
       "      <td>0.895673</td>\n",
       "      <td>0.997508</td>\n",
       "      <td>0.899502</td>\n",
       "      <td>0.996984</td>\n",
       "      <td>0.936520</td>\n",
       "      <td>0.179657</td>\n",
       "      <td>0.002450</td>\n",
       "      <td>0.000262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.757375</td>\n",
       "      <td>0.764448</td>\n",
       "      <td>0.896192</td>\n",
       "      <td>0.998098</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>230</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'n...</td>\n",
       "      <td>21</td>\n",
       "      <td>0.893451</td>\n",
       "      <td>0.998168</td>\n",
       "      <td>0.895420</td>\n",
       "      <td>0.998122</td>\n",
       "      <td>0.899705</td>\n",
       "      <td>0.998003</td>\n",
       "      <td>0.036111</td>\n",
       "      <td>0.074226</td>\n",
       "      <td>0.002611</td>\n",
       "      <td>0.000070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>26.268595</td>\n",
       "      <td>1.415954</td>\n",
       "      <td>0.896132</td>\n",
       "      <td>0.997379</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>450</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>22</td>\n",
       "      <td>0.893714</td>\n",
       "      <td>0.997583</td>\n",
       "      <td>0.895312</td>\n",
       "      <td>0.997512</td>\n",
       "      <td>0.899370</td>\n",
       "      <td>0.997043</td>\n",
       "      <td>0.985520</td>\n",
       "      <td>0.033880</td>\n",
       "      <td>0.002381</td>\n",
       "      <td>0.000239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.486490</td>\n",
       "      <td>0.990767</td>\n",
       "      <td>0.896105</td>\n",
       "      <td>0.998089</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>230</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>23</td>\n",
       "      <td>0.893100</td>\n",
       "      <td>0.998185</td>\n",
       "      <td>0.896017</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.899199</td>\n",
       "      <td>0.997957</td>\n",
       "      <td>0.411689</td>\n",
       "      <td>0.210757</td>\n",
       "      <td>0.002491</td>\n",
       "      <td>0.000096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>47.970499</td>\n",
       "      <td>3.356192</td>\n",
       "      <td>0.895912</td>\n",
       "      <td>0.997400</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>24</td>\n",
       "      <td>0.893245</td>\n",
       "      <td>0.997614</td>\n",
       "      <td>0.895339</td>\n",
       "      <td>0.997541</td>\n",
       "      <td>0.899151</td>\n",
       "      <td>0.997047</td>\n",
       "      <td>1.012969</td>\n",
       "      <td>0.285226</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.000252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>42.254164</td>\n",
       "      <td>2.990953</td>\n",
       "      <td>0.895900</td>\n",
       "      <td>0.997406</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>890</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.893213</td>\n",
       "      <td>0.997610</td>\n",
       "      <td>0.895394</td>\n",
       "      <td>0.997524</td>\n",
       "      <td>0.899094</td>\n",
       "      <td>0.997084</td>\n",
       "      <td>0.784449</td>\n",
       "      <td>0.107984</td>\n",
       "      <td>0.002428</td>\n",
       "      <td>0.000230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>36.919256</td>\n",
       "      <td>3.085349</td>\n",
       "      <td>0.895734</td>\n",
       "      <td>0.997397</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>780</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>26</td>\n",
       "      <td>0.892990</td>\n",
       "      <td>0.997585</td>\n",
       "      <td>0.895229</td>\n",
       "      <td>0.997519</td>\n",
       "      <td>0.898984</td>\n",
       "      <td>0.997087</td>\n",
       "      <td>0.801016</td>\n",
       "      <td>0.191854</td>\n",
       "      <td>0.002473</td>\n",
       "      <td>0.000221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>31.404116</td>\n",
       "      <td>2.355657</td>\n",
       "      <td>0.895658</td>\n",
       "      <td>0.997395</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>670</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>27</td>\n",
       "      <td>0.892555</td>\n",
       "      <td>0.997586</td>\n",
       "      <td>0.895503</td>\n",
       "      <td>0.997512</td>\n",
       "      <td>0.898918</td>\n",
       "      <td>0.997087</td>\n",
       "      <td>0.675549</td>\n",
       "      <td>0.136748</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.000220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>21.164863</td>\n",
       "      <td>1.654403</td>\n",
       "      <td>0.895580</td>\n",
       "      <td>0.997382</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>450</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>28</td>\n",
       "      <td>0.892728</td>\n",
       "      <td>0.997557</td>\n",
       "      <td>0.895281</td>\n",
       "      <td>0.997532</td>\n",
       "      <td>0.898730</td>\n",
       "      <td>0.997058</td>\n",
       "      <td>0.212479</td>\n",
       "      <td>0.069642</td>\n",
       "      <td>0.002459</td>\n",
       "      <td>0.000230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25.405160</td>\n",
       "      <td>1.986648</td>\n",
       "      <td>0.895562</td>\n",
       "      <td>0.997393</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>560</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>29</td>\n",
       "      <td>0.892427</td>\n",
       "      <td>0.997581</td>\n",
       "      <td>0.895235</td>\n",
       "      <td>0.997534</td>\n",
       "      <td>0.899024</td>\n",
       "      <td>0.997063</td>\n",
       "      <td>0.853966</td>\n",
       "      <td>0.091361</td>\n",
       "      <td>0.002703</td>\n",
       "      <td>0.000234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>13.367344</td>\n",
       "      <td>0.885916</td>\n",
       "      <td>0.895544</td>\n",
       "      <td>0.997337</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>230</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>30</td>\n",
       "      <td>0.892698</td>\n",
       "      <td>0.997526</td>\n",
       "      <td>0.895291</td>\n",
       "      <td>0.997490</td>\n",
       "      <td>0.898643</td>\n",
       "      <td>0.996994</td>\n",
       "      <td>0.253325</td>\n",
       "      <td>0.143835</td>\n",
       "      <td>0.002434</td>\n",
       "      <td>0.000243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>17.084100</td>\n",
       "      <td>1.283689</td>\n",
       "      <td>0.895333</td>\n",
       "      <td>0.997367</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>340</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>31</td>\n",
       "      <td>0.892007</td>\n",
       "      <td>0.997562</td>\n",
       "      <td>0.895387</td>\n",
       "      <td>0.997529</td>\n",
       "      <td>0.898606</td>\n",
       "      <td>0.997008</td>\n",
       "      <td>0.745425</td>\n",
       "      <td>0.118976</td>\n",
       "      <td>0.002694</td>\n",
       "      <td>0.000254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6.530159</td>\n",
       "      <td>0.532993</td>\n",
       "      <td>0.895206</td>\n",
       "      <td>0.998021</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>120</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.891831</td>\n",
       "      <td>0.998108</td>\n",
       "      <td>0.894237</td>\n",
       "      <td>0.998028</td>\n",
       "      <td>0.899550</td>\n",
       "      <td>0.997927</td>\n",
       "      <td>0.492333</td>\n",
       "      <td>0.068714</td>\n",
       "      <td>0.003225</td>\n",
       "      <td>0.000074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.048533</td>\n",
       "      <td>0.381539</td>\n",
       "      <td>0.895148</td>\n",
       "      <td>0.998044</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>120</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'n...</td>\n",
       "      <td>33</td>\n",
       "      <td>0.891822</td>\n",
       "      <td>0.998080</td>\n",
       "      <td>0.894581</td>\n",
       "      <td>0.998076</td>\n",
       "      <td>0.899040</td>\n",
       "      <td>0.997977</td>\n",
       "      <td>0.074377</td>\n",
       "      <td>0.010889</td>\n",
       "      <td>0.002974</td>\n",
       "      <td>0.000048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.924277</td>\n",
       "      <td>0.426418</td>\n",
       "      <td>0.894464</td>\n",
       "      <td>0.997216</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>120</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>34</td>\n",
       "      <td>0.891605</td>\n",
       "      <td>0.997418</td>\n",
       "      <td>0.893235</td>\n",
       "      <td>0.997341</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.996891</td>\n",
       "      <td>0.259507</td>\n",
       "      <td>0.018917</td>\n",
       "      <td>0.002966</td>\n",
       "      <td>0.000232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11.169140</td>\n",
       "      <td>0.972104</td>\n",
       "      <td>0.894423</td>\n",
       "      <td>0.997345</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>230</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>35</td>\n",
       "      <td>0.891108</td>\n",
       "      <td>0.997563</td>\n",
       "      <td>0.893923</td>\n",
       "      <td>0.997472</td>\n",
       "      <td>0.898238</td>\n",
       "      <td>0.996998</td>\n",
       "      <td>0.280673</td>\n",
       "      <td>0.137208</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>0.000248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>7.204828</td>\n",
       "      <td>0.415857</td>\n",
       "      <td>0.894119</td>\n",
       "      <td>0.997262</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>120</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>36</td>\n",
       "      <td>0.891550</td>\n",
       "      <td>0.997419</td>\n",
       "      <td>0.892936</td>\n",
       "      <td>0.997381</td>\n",
       "      <td>0.897870</td>\n",
       "      <td>0.996986</td>\n",
       "      <td>0.468300</td>\n",
       "      <td>0.040085</td>\n",
       "      <td>0.002712</td>\n",
       "      <td>0.000196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.487526</td>\n",
       "      <td>0.038494</td>\n",
       "      <td>0.873927</td>\n",
       "      <td>0.995821</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>37</td>\n",
       "      <td>0.869628</td>\n",
       "      <td>0.995951</td>\n",
       "      <td>0.872614</td>\n",
       "      <td>0.995899</td>\n",
       "      <td>0.879538</td>\n",
       "      <td>0.995612</td>\n",
       "      <td>0.004476</td>\n",
       "      <td>0.000855</td>\n",
       "      <td>0.004151</td>\n",
       "      <td>0.000149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.332551</td>\n",
       "      <td>0.038746</td>\n",
       "      <td>0.872977</td>\n",
       "      <td>0.995910</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'n...</td>\n",
       "      <td>38</td>\n",
       "      <td>0.869026</td>\n",
       "      <td>0.996015</td>\n",
       "      <td>0.872175</td>\n",
       "      <td>0.995868</td>\n",
       "      <td>0.877731</td>\n",
       "      <td>0.995849</td>\n",
       "      <td>0.049991</td>\n",
       "      <td>0.002448</td>\n",
       "      <td>0.003599</td>\n",
       "      <td>0.000074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.609454</td>\n",
       "      <td>0.051354</td>\n",
       "      <td>0.872386</td>\n",
       "      <td>0.994959</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>39</td>\n",
       "      <td>0.867526</td>\n",
       "      <td>0.995367</td>\n",
       "      <td>0.874439</td>\n",
       "      <td>0.994861</td>\n",
       "      <td>0.875193</td>\n",
       "      <td>0.994650</td>\n",
       "      <td>0.081397</td>\n",
       "      <td>0.018086</td>\n",
       "      <td>0.003450</td>\n",
       "      <td>0.000301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.744856</td>\n",
       "      <td>0.046773</td>\n",
       "      <td>0.870728</td>\n",
       "      <td>0.994810</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>40</td>\n",
       "      <td>0.867490</td>\n",
       "      <td>0.994954</td>\n",
       "      <td>0.869198</td>\n",
       "      <td>0.994810</td>\n",
       "      <td>0.875497</td>\n",
       "      <td>0.994665</td>\n",
       "      <td>0.118948</td>\n",
       "      <td>0.002141</td>\n",
       "      <td>0.003444</td>\n",
       "      <td>0.000118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "18      48.395469         3.825982         0.897264          0.998138   \n",
       "16      37.419543         2.961567         0.897248          0.998130   \n",
       "19      56.035860         3.788953         0.897244          0.998139   \n",
       "17      42.341748         3.100389         0.897123          0.998136   \n",
       "15      29.182102         2.295158         0.897005          0.998133   \n",
       "14      24.451602         1.752896         0.896987          0.998122   \n",
       "8       39.529309         3.353667         0.896701          0.998138   \n",
       "9       48.145448         3.716241         0.896669          0.998139   \n",
       "7       33.959718         2.785672         0.896637          0.998135   \n",
       "36      34.654465         2.194206         0.896564          0.997393   \n",
       "3       14.892130         1.183849         0.896536          0.998112   \n",
       "5       23.809666         1.845498         0.896509          0.998139   \n",
       "4       19.358596         1.488175         0.896504          0.998136   \n",
       "35      29.092304         1.862562         0.896485          0.997386   \n",
       "6       28.230006         2.223272         0.896429          0.998136   \n",
       "39      37.938799         1.949409         0.896425          0.997419   \n",
       "38      42.238346         2.189633         0.896414          0.997422   \n",
       "37      41.215544         2.439488         0.896400          0.997400   \n",
       "13      17.711762         1.251416         0.896377          0.998095   \n",
       "33      20.523469         1.268593         0.896254          0.997353   \n",
       "2        9.757375         0.764448         0.896192          0.998098   \n",
       "34      26.268595         1.415954         0.896132          0.997379   \n",
       "12      13.486490         0.990767         0.896105          0.998089   \n",
       "29      47.970499         3.356192         0.895912          0.997400   \n",
       "28      42.254164         2.990953         0.895900          0.997406   \n",
       "27      36.919256         3.085349         0.895734          0.997397   \n",
       "26      31.404116         2.355657         0.895658          0.997395   \n",
       "24      21.164863         1.654403         0.895580          0.997382   \n",
       "25      25.405160         1.986648         0.895562          0.997393   \n",
       "32      13.367344         0.885916         0.895544          0.997337   \n",
       "23      17.084100         1.283689         0.895333          0.997367   \n",
       "11       6.530159         0.532993         0.895206          0.998021   \n",
       "1        5.048533         0.381539         0.895148          0.998044   \n",
       "21       5.924277         0.426418         0.894464          0.997216   \n",
       "22      11.169140         0.972104         0.894423          0.997345   \n",
       "31       7.204828         0.415857         0.894119          0.997262   \n",
       "10       0.487526         0.038494         0.873927          0.995821   \n",
       "0        0.332551         0.038746         0.872977          0.995910   \n",
       "20       0.609454         0.051354         0.872386          0.994959   \n",
       "30       0.744856         0.046773         0.870728          0.994810   \n",
       "\n",
       "   param_class_weight param_criterion param_n_estimators  \\\n",
       "18               None         entropy                890   \n",
       "16               None         entropy                670   \n",
       "19               None         entropy               1000   \n",
       "17               None         entropy                780   \n",
       "15               None         entropy                560   \n",
       "14               None         entropy                450   \n",
       "8                None            gini                890   \n",
       "9                None            gini               1000   \n",
       "7                None            gini                780   \n",
       "36           balanced         entropy                670   \n",
       "3                None            gini                340   \n",
       "5                None            gini                560   \n",
       "4                None            gini                450   \n",
       "35           balanced         entropy                560   \n",
       "6                None            gini                670   \n",
       "39           balanced         entropy               1000   \n",
       "38           balanced         entropy                890   \n",
       "37           balanced         entropy                780   \n",
       "13               None         entropy                340   \n",
       "33           balanced         entropy                340   \n",
       "2                None            gini                230   \n",
       "34           balanced         entropy                450   \n",
       "12               None         entropy                230   \n",
       "29           balanced            gini               1000   \n",
       "28           balanced            gini                890   \n",
       "27           balanced            gini                780   \n",
       "26           balanced            gini                670   \n",
       "24           balanced            gini                450   \n",
       "25           balanced            gini                560   \n",
       "32           balanced         entropy                230   \n",
       "23           balanced            gini                340   \n",
       "11               None         entropy                120   \n",
       "1                None            gini                120   \n",
       "21           balanced            gini                120   \n",
       "22           balanced            gini                230   \n",
       "31           balanced         entropy                120   \n",
       "10               None         entropy                 10   \n",
       "0                None            gini                 10   \n",
       "20           balanced            gini                 10   \n",
       "30           balanced         entropy                 10   \n",
       "\n",
       "                                               params  rank_test_score  \\\n",
       "18  {'class_weight': None, 'criterion': 'entropy',...                1   \n",
       "16  {'class_weight': None, 'criterion': 'entropy',...                2   \n",
       "19  {'class_weight': None, 'criterion': 'entropy',...                3   \n",
       "17  {'class_weight': None, 'criterion': 'entropy',...                4   \n",
       "15  {'class_weight': None, 'criterion': 'entropy',...                5   \n",
       "14  {'class_weight': None, 'criterion': 'entropy',...                6   \n",
       "8   {'class_weight': None, 'criterion': 'gini', 'n...                7   \n",
       "9   {'class_weight': None, 'criterion': 'gini', 'n...                8   \n",
       "7   {'class_weight': None, 'criterion': 'gini', 'n...                9   \n",
       "36  {'class_weight': 'balanced', 'criterion': 'ent...               10   \n",
       "3   {'class_weight': None, 'criterion': 'gini', 'n...               11   \n",
       "5   {'class_weight': None, 'criterion': 'gini', 'n...               12   \n",
       "4   {'class_weight': None, 'criterion': 'gini', 'n...               13   \n",
       "35  {'class_weight': 'balanced', 'criterion': 'ent...               14   \n",
       "6   {'class_weight': None, 'criterion': 'gini', 'n...               15   \n",
       "39  {'class_weight': 'balanced', 'criterion': 'ent...               16   \n",
       "38  {'class_weight': 'balanced', 'criterion': 'ent...               17   \n",
       "37  {'class_weight': 'balanced', 'criterion': 'ent...               18   \n",
       "13  {'class_weight': None, 'criterion': 'entropy',...               19   \n",
       "33  {'class_weight': 'balanced', 'criterion': 'ent...               20   \n",
       "2   {'class_weight': None, 'criterion': 'gini', 'n...               21   \n",
       "34  {'class_weight': 'balanced', 'criterion': 'ent...               22   \n",
       "12  {'class_weight': None, 'criterion': 'entropy',...               23   \n",
       "29  {'class_weight': 'balanced', 'criterion': 'gin...               24   \n",
       "28  {'class_weight': 'balanced', 'criterion': 'gin...               25   \n",
       "27  {'class_weight': 'balanced', 'criterion': 'gin...               26   \n",
       "26  {'class_weight': 'balanced', 'criterion': 'gin...               27   \n",
       "24  {'class_weight': 'balanced', 'criterion': 'gin...               28   \n",
       "25  {'class_weight': 'balanced', 'criterion': 'gin...               29   \n",
       "32  {'class_weight': 'balanced', 'criterion': 'ent...               30   \n",
       "23  {'class_weight': 'balanced', 'criterion': 'gin...               31   \n",
       "11  {'class_weight': None, 'criterion': 'entropy',...               32   \n",
       "1   {'class_weight': None, 'criterion': 'gini', 'n...               33   \n",
       "21  {'class_weight': 'balanced', 'criterion': 'gin...               34   \n",
       "22  {'class_weight': 'balanced', 'criterion': 'gin...               35   \n",
       "31  {'class_weight': 'balanced', 'criterion': 'ent...               36   \n",
       "10  {'class_weight': None, 'criterion': 'entropy',...               37   \n",
       "0   {'class_weight': None, 'criterion': 'gini', 'n...               38   \n",
       "20  {'class_weight': 'balanced', 'criterion': 'gin...               39   \n",
       "30  {'class_weight': 'balanced', 'criterion': 'ent...               40   \n",
       "\n",
       "    split0_test_score  split0_train_score  split1_test_score  \\\n",
       "18           0.894322            0.998229           0.896448   \n",
       "16           0.894501            0.998228           0.896451   \n",
       "19           0.894072            0.998229           0.896487   \n",
       "17           0.894375            0.998222           0.896254   \n",
       "15           0.894167            0.998228           0.896365   \n",
       "14           0.894299            0.998227           0.896358   \n",
       "8            0.893811            0.998224           0.895982   \n",
       "9            0.893764            0.998226           0.896117   \n",
       "7            0.893648            0.998226           0.895913   \n",
       "36           0.894296            0.997597           0.895903   \n",
       "3            0.893929            0.998192           0.895686   \n",
       "5            0.893609            0.998231           0.895805   \n",
       "4            0.893830            0.998224           0.895593   \n",
       "35           0.894056            0.997584           0.895671   \n",
       "6            0.893536            0.998230           0.895759   \n",
       "39           0.893898            0.997612           0.895982   \n",
       "38           0.893771            0.997623           0.895836   \n",
       "37           0.893884            0.997605           0.895749   \n",
       "13           0.893707            0.998202           0.896100   \n",
       "33           0.893587            0.997567           0.895673   \n",
       "2            0.893451            0.998168           0.895420   \n",
       "34           0.893714            0.997583           0.895312   \n",
       "12           0.893100            0.998185           0.896017   \n",
       "29           0.893245            0.997614           0.895339   \n",
       "28           0.893213            0.997610           0.895394   \n",
       "27           0.892990            0.997585           0.895229   \n",
       "26           0.892555            0.997586           0.895503   \n",
       "24           0.892728            0.997557           0.895281   \n",
       "25           0.892427            0.997581           0.895235   \n",
       "32           0.892698            0.997526           0.895291   \n",
       "23           0.892007            0.997562           0.895387   \n",
       "11           0.891831            0.998108           0.894237   \n",
       "1            0.891822            0.998080           0.894581   \n",
       "21           0.891605            0.997418           0.893235   \n",
       "22           0.891108            0.997563           0.893923   \n",
       "31           0.891550            0.997419           0.892936   \n",
       "10           0.869628            0.995951           0.872614   \n",
       "0            0.869026            0.996015           0.872175   \n",
       "20           0.867526            0.995367           0.874439   \n",
       "30           0.867490            0.994954           0.869198   \n",
       "\n",
       "    split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "18            0.998153           0.901023            0.998032      1.722333   \n",
       "16            0.998141           0.900792            0.998021      1.058009   \n",
       "19            0.998146           0.901173            0.998042      1.453320   \n",
       "17            0.998156           0.900739            0.998031      1.235332   \n",
       "15            0.998151           0.900484            0.998021      0.463407   \n",
       "14            0.998126           0.900303            0.998014      0.518100   \n",
       "8             0.998142           0.900310            0.998048      2.404425   \n",
       "9             0.998144           0.900128            0.998045      2.437924   \n",
       "7             0.998130           0.900351            0.998050      0.768166   \n",
       "36            0.997535           0.899494            0.997047      0.568587   \n",
       "3             0.998135           0.899993            0.998010      0.685280   \n",
       "5             0.998149           0.900112            0.998038      0.987909   \n",
       "4             0.998149           0.900089            0.998034      0.327186   \n",
       "35            0.997530           0.899728            0.997043      0.817800   \n",
       "6             0.998133           0.899993            0.998045      0.818327   \n",
       "39            0.997572           0.899396            0.997073      4.150428   \n",
       "38            0.997563           0.899636            0.997079      1.035562   \n",
       "37            0.997551           0.899569            0.997045      1.107557   \n",
       "13            0.998102           0.899324            0.997980      0.519022   \n",
       "33            0.997508           0.899502            0.996984      0.936520   \n",
       "2             0.998122           0.899705            0.998003      0.036111   \n",
       "34            0.997512           0.899370            0.997043      0.985520   \n",
       "12            0.998125           0.899199            0.997957      0.411689   \n",
       "29            0.997541           0.899151            0.997047      1.012969   \n",
       "28            0.997524           0.899094            0.997084      0.784449   \n",
       "27            0.997519           0.898984            0.997087      0.801016   \n",
       "26            0.997512           0.898918            0.997087      0.675549   \n",
       "24            0.997532           0.898730            0.997058      0.212479   \n",
       "25            0.997534           0.899024            0.997063      0.853966   \n",
       "32            0.997490           0.898643            0.996994      0.253325   \n",
       "23            0.997529           0.898606            0.997008      0.745425   \n",
       "11            0.998028           0.899550            0.997927      0.492333   \n",
       "1             0.998076           0.899040            0.997977      0.074377   \n",
       "21            0.997341           0.898551            0.996891      0.259507   \n",
       "22            0.997472           0.898238            0.996998      0.280673   \n",
       "31            0.997381           0.897870            0.996986      0.468300   \n",
       "10            0.995899           0.879538            0.995612      0.004476   \n",
       "0             0.995868           0.877731            0.995849      0.049991   \n",
       "20            0.994861           0.875193            0.994650      0.081397   \n",
       "30            0.994810           0.875497            0.994665      0.118948   \n",
       "\n",
       "    std_score_time  std_test_score  std_train_score  \n",
       "18        0.315958        0.002796         0.000081  \n",
       "16        0.130893        0.002629         0.000085  \n",
       "19        0.025295        0.002948         0.000076  \n",
       "17        0.239111        0.002669         0.000079  \n",
       "15        0.318522        0.002618         0.000085  \n",
       "14        0.179451        0.002491         0.000087  \n",
       "8         0.397396        0.002701         0.000072  \n",
       "9         0.189916        0.002627         0.000074  \n",
       "7         0.143435        0.002784         0.000072  \n",
       "36        0.067388        0.002173         0.000246  \n",
       "3         0.051733        0.002547         0.000076  \n",
       "5         0.044797        0.002701         0.000079  \n",
       "4         0.019576        0.002635         0.000078  \n",
       "35        0.069652        0.002386         0.000243  \n",
       "6         0.029125        0.002678         0.000075  \n",
       "39        0.178393        0.002266         0.000245  \n",
       "38        0.334611        0.002429         0.000244  \n",
       "37        0.060664        0.002366         0.000252  \n",
       "13        0.109759        0.002301         0.000091  \n",
       "33        0.179657        0.002450         0.000262  \n",
       "2         0.074226        0.002611         0.000070  \n",
       "34        0.033880        0.002381         0.000239  \n",
       "12        0.210757        0.002491         0.000096  \n",
       "29        0.285226        0.002445         0.000252  \n",
       "28        0.107984        0.002428         0.000230  \n",
       "27        0.191854        0.002473         0.000221  \n",
       "26        0.136748        0.002600         0.000220  \n",
       "24        0.069642        0.002459         0.000230  \n",
       "25        0.091361        0.002703         0.000234  \n",
       "32        0.143835        0.002434         0.000243  \n",
       "23        0.118976        0.002694         0.000254  \n",
       "11        0.068714        0.003225         0.000074  \n",
       "1         0.010889        0.002974         0.000048  \n",
       "21        0.018917        0.002966         0.000232  \n",
       "22        0.137208        0.002932         0.000248  \n",
       "31        0.040085        0.002712         0.000196  \n",
       "10        0.000855        0.004151         0.000149  \n",
       "0         0.002448        0.003599         0.000074  \n",
       "20        0.018086        0.003450         0.000301  \n",
       "30        0.002141        0.003444         0.000118  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_).sort_values(by=\"rank_test_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GridSearchCV` al estar ajustado se convierte en un estimador, por lo cual podemos usar el método predict, por debajo simplemente se usará el mejor estimador `grid.best_estimator_`. \n",
    "\n",
    "Para añadir el funcionamiento del mejor estimador obtenido por el modelo con nuestra funcion `evaluar_modelo` no usamos el objeto grid en si, ya que la funcion `cross_validate` hace multiples ajustes y evaluaciones (volveriamos a esperar los 8 minutos que a tardado un ajuste multiplicado por el número de validaciones cruzadas!).\n",
    "\n",
    "Para evaluar el funcionamiento del mejor estimador simplemente usamos la funcion con el mejor estimador directamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resultados[\"rf_gridsearch\"] = evaluar_modelo(grid.best_estimator_, censo_X_procesado, censo_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Ahora vamos a realizar la misma optimización de parámetros pero usando `RandomizedSearchCV`. RandomizedSearchCV funciona de forma similar a GridSearchCV, pero en vez de evaluar todas las combinaciones posibles de hiperparámetros, se toman n muestras de hiperparámetros de dichas distribuciones.\n",
    "\n",
    "Se recomienda usar distribuciones en vez de valores fijos para hiperparámetros continuos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero vamos a evaluar el funcionamiento de la busqueda aleatoria con los mísmos hiperparámetros que hemos usado en la busqueda en malla. Para `RandomizedSearchCV` tenemos que indicarle cuantas variantes de hiperparámetros utilizar (definidas por el parámetro n_iter, por defecto toma 10 variantes). Dado que dicha búsqueda toma muestreos el parámetro ya no se llama `param_grid` sino `param_distributions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "busqueda_random = RandomizedSearchCV(estimator=estimador_rf, \n",
    "                    param_distributions=parametros_busqueda_rf,\n",
    "                   scoring=\"roc_auc\", n_jobs=-1, n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "busqueda_random.fit(censo_X_procesado, censo_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La búsqueda con 10 iteraciones ha tardado 1min 25s en mi máquina. Veamos como ha funcionado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.896926092788\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=340, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(busqueda_random.best_score_)\n",
    "print(busqueda_random.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La búsqueda de malla obtuvo un ROC AUC máximo de 0.89726431782 versus 0.896926092788 obtenido por la búsqueda aleatoria. Sin embargo la busqueda aleatoria ha tardado 8 veces menos!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resultados[\"rf_randomizedsearch\"] = evaluar_modelo(grid.best_estimator_, censo_X_procesado, censo_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una ventaja del Randomized Search es que nos permite evaluar un espacio de hiperparámetros más amplio para un tiempo de computación similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ver esto vamos a ampliar el espacio de búsqueda de hiperparámetros y hacer 100 muestreos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "param_dist_random = {\n",
    "    \"max_depth\": [3, None],\n",
    "    \"max_features\": sp_randint(1, 11),\n",
    "    \"min_samples_split\": sp_randint(2, 11),\n",
    "    \"min_samples_leaf\": sp_randint(1, 11),\n",
    "    \"bootstrap\": [True, False],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"n_estimators\": np.linspace(10,1000,10).astype(int),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "busqueda_random_100 = RandomizedSearchCV(estimator=estimador_rf, \n",
    "                    param_distributions=param_dist_random,\n",
    "                   scoring=\"roc_auc\", n_jobs=-1, n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14min 55s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "busqueda_random_100.fit(censo_X_procesado, censo_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En mi máquina esta búsqueda ha tardado 8 minutos 54 segundos, un poco más que el grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91950285418\n",
      "RandomForestClassifier(bootstrap=False, class_weight=None,\n",
      "            criterion='entropy', max_depth=None, max_features=10,\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=3,\n",
      "            min_samples_split=10, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=1000, n_jobs=1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(busqueda_random_100.best_score_)\n",
    "print(busqueda_random_100.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "La búsqueda aleatoria con los nuevos parámetros ha tardado un tiempo similar a la busqueda en malla, pero ha obtenido una puntuación máxima ROC AUC de 0.91950285418 (versus 0.89726431782 de la busqueda en malla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resultados[\"rf_randomizedsearch_100\"] = evaluar_modelo(busqueda_random_100.best_estimator_,\n",
    "                                                      censo_X_procesado, censo_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el estimador obtenido con la búsqueda aleatoria es el que mejor funciona.\n",
    "\n",
    "En general, salvo que el espacio de hiperparámetros que queramos explorar sea pequeño, es mejor el utilizar `RandomizedSearchCV` en vez de `GridSearchCV`. Esto es así por que en general no existe un unico conjunto de hiperparámetros que obtiene el mejor funcionamiento, sino que suelen existir multiples \"areas\" en el espacio dimensional de los hiperparámetros que funcionan de forma similar. Al hacer una búsqueda aleatoria podemos explorar las diversas areas en un tiempo más reducido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimización de parámetros dentro de un Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los algoritmos de busqueda de sklearn siguen la API de transformadores y estimadores. Esto significa que podemos crear un pipeline e incluir la optimización de hiperparámetros dentro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "busqueda_random_10 = RandomizedSearchCV(estimator=estimador_rf, \n",
    "                    param_distributions=param_dist_random,\n",
    "                   scoring=\"roc_auc\", n_jobs=-1, n_iter=10)\n",
    "\n",
    "pipeline_estimador = Pipeline(\n",
    "    [\n",
    "     (\"procesado\", pipeline_procesado),\n",
    "     (\"estimador\", busqueda_random_10)   \n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos ajustar directamente en los datos originales sin tener que preprocesarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('procesado', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('transformacion_numericas', Pipeline(memory=None,\n",
       "     steps=[('selector_numerico', <__main__.ColumnExtractor object at 0x7f0962060dd8>), ('imputador', Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)),...', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring='roc_auc', verbose=0))])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_estimador.fit(censo_X, censo_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_estimador.predict(censo_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay varias librerias externas que permiten hacer optimización de parámetros de forma más flexible y/o compleja que las implementaciones que soporta scikit-learn por defecto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Scikit-optimize [(link)](https://scikit-optimize.github.io/)\n",
    "\n",
    "Scikit-Optimize, o skopt, es una librería que implementa multiples metodos para optimizar hiperparámetros de forma secuencial.\n",
    "\n",
    "Se instala con:\n",
    "\n",
    "`{sys.executable} -m pip install scikit-optimize` (existe una version en conda-forge pero solo de una version antigua)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La api de scikit-optimize no es tan similar a la de sklearn como seria posible, no obstante es muy facil de usar. Permite usar diversos algoritmos para ayudar al proceso de optimización, por ejemplo procesos gausianos o Bosques aleatorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import skopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skopt.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skopt import gp_minimize "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En vez de usar un diccionario con el espacio de hiperparámetros que queremos buscar, scikit-optimize necesita pasarle una lista de parámetros.\n",
    "\n",
    "skopt es una libreria relativamente nueva, y tiene ciertas limitaciones comparada con scikitlearn. Por ejemplo, en vez de diccionarios con los nombres de los parámetros,  espera como inputs listas, no se pueden usar funciones de distribuciones (como scipy.randint)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skopt import space\n",
    "\n",
    "param_espacio_skopt = [\n",
    "    space.Integer(3, 10), #max_depth\n",
    "    space.Integer(1, 11), #max_features\n",
    "    (0.001, 0.99, \"uniform\"), #min_samples_split\n",
    "    (0.001, 0.5, \"uniform\"), #min_samples_leaf\n",
    "    space.Integer(1, 1000), #n_estimators\n",
    "    space.Categorical([\"gini\", \"entropy\"]), #criterion,\n",
    "    space.Categorical([True, False]), #bootstrap\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-optimize necesita que definamos la funcion objetivo, que ira variando en funcion de los parámetros elegidos. Dicha función tiene que crear el estimador y evaluarlo y devolver la evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "estimador_rf = RandomForestClassifier()\n",
    "\n",
    "def funcion_optimizable(params):\n",
    "    #params es simplemente una selección especifica de hiperparámetros\n",
    "    max_depth, max_features, min_samples_split, min_samples_leaf,  n_estimators, criterion, bootstrap = params\n",
    "\n",
    "    estimador_rf.set_params(\n",
    "                   max_depth=max_depth,\n",
    "                   max_features=max_features,\n",
    "                   min_samples_split=min_samples_split, \n",
    "                   min_samples_leaf=min_samples_leaf,\n",
    "                   n_estimators=n_estimators,\n",
    "                   criterion=criterion\n",
    "                  )\n",
    "\n",
    "    return -np.mean(cross_val_score(estimador_rf, censo_X_procesado, censo_y, cv=5, n_jobs=-1,\n",
    "                                    scoring=\"roc_auc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos dejar que skopt optimize los outputs de la funcion `funcion_optimizable` mediante el uso de `gp_minimize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manuel/anaconda3/envs/data/lib/python3.6/site-packages/skopt/optimizer/optimizer.py:366: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/manuel/anaconda3/envs/data/lib/python3.6/site-packages/skopt/optimizer/optimizer.py:366: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/manuel/anaconda3/envs/data/lib/python3.6/site-packages/skopt/optimizer/optimizer.py:366: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/home/manuel/anaconda3/envs/data/lib/python3.6/site-packages/skopt/optimizer/optimizer.py:366: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25min 31s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "resultado_gp = gp_minimize(funcion_optimizable, param_espacio_skopt, n_calls=100, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "este proceso ha tardado 25 minutos en mi maquina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El parámetro `x` nos da el vector con los parámetros con mejor funcionamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 10, 2, 3, 46, 'gini']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado_gp.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimador_skopt_gp_100 = RandomForestClassifier(\n",
    "    max_depth=resultado_gp.x[0],\n",
    "    max_features=resultado_gp.x[1],\n",
    "    min_samples_split=resultado_gp.x[2], \n",
    "    min_samples_leaf=resultado_gp.x[3],\n",
    "    n_estimators=resultado_gp.x[4],\n",
    "    criterion=resultado_gp.x[5]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resultados[\"rf_skopt_gp_100\"] = evaluar_modelo(estimador_skopt_gp_100, censo_X_procesado, censo_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "skopt (version >0.4) tambien tiene una implementacion de `BayesSearchCV`, que es un reemplazo de GridSearchCV pero que usa optimización bayesiana (en vez de probar todas las posibilidades)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV \n",
    "\n",
    "param_espacio_skopt_bayesCV = {\n",
    "     \"max_depth\": space.Integer(3, 10), #\n",
    "    \"max_features\": space.Integer(1, 11), #\n",
    "    \"min_samples_split\": space.Real(0.001, 0.99, \"uniform\"), #\n",
    "    \"min_samples_leaf\": space.Real(0.001, 0.5, \"uniform\"), #\n",
    "    \"n_estimators\": space.Integer(1, 1000), #\n",
    "    \"criterion\": space.Categorical([\"gini\", \"entropy\"]),\n",
    "    \"boostrap\": space.Categorical([True, False])\n",
    "}\n",
    "\n",
    "busqueda_bayesiano_skopt_100 = BayesSearchCV(\n",
    "    estimator=estimador_rf, \n",
    "    search_spaces=param_espacio_skopt_bayesCV,\n",
    "    scoring=\"roc_auc\", n_jobs=-1, n_iter=100,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10min 39s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "busqueda_bayesiano_skopt_100.fit(censo_X_procesado, censo_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'entropy',\n",
       " 'max_depth': 10,\n",
       " 'max_features': 11,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 0.001,\n",
       " 'min_samples_split': 0.001,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 212,\n",
       " 'n_jobs': 1,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "busqueda_bayesiano_skopt_100.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resultados[\"rf_bayesiano_skopt_100\"] = evaluar_modelo(busqueda_bayesiano_skopt_100.best_estimator_,\n",
    "                                                      censo_X_procesado, censo_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "      <th>fit_time_idx</th>\n",
       "      <th>score_time_idx</th>\n",
       "      <th>test_score_idx</th>\n",
       "      <th>train_score_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>naive_bayes</th>\n",
       "      <td>0.066678</td>\n",
       "      <td>0.014363</td>\n",
       "      <td>0.781202</td>\n",
       "      <td>0.783341</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>0.010738</td>\n",
       "      <td>0.849714</td>\n",
       "      <td>0.786865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_logistica</th>\n",
       "      <td>0.460645</td>\n",
       "      <td>0.018298</td>\n",
       "      <td>0.906715</td>\n",
       "      <td>0.908326</td>\n",
       "      <td>0.007205</td>\n",
       "      <td>0.013680</td>\n",
       "      <td>0.986234</td>\n",
       "      <td>0.912413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.395003</td>\n",
       "      <td>0.017742</td>\n",
       "      <td>0.874312</td>\n",
       "      <td>0.995521</td>\n",
       "      <td>0.006179</td>\n",
       "      <td>0.013264</td>\n",
       "      <td>0.950989</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_bayesiano_skopt_100</th>\n",
       "      <td>7.136472</td>\n",
       "      <td>0.193855</td>\n",
       "      <td>0.910383</td>\n",
       "      <td>0.914396</td>\n",
       "      <td>0.111627</td>\n",
       "      <td>0.144932</td>\n",
       "      <td>0.990223</td>\n",
       "      <td>0.918510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_gridsearch</th>\n",
       "      <td>3.986320</td>\n",
       "      <td>0.236890</td>\n",
       "      <td>0.848783</td>\n",
       "      <td>0.849026</td>\n",
       "      <td>0.062353</td>\n",
       "      <td>0.177107</td>\n",
       "      <td>0.923221</td>\n",
       "      <td>0.852846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_randomizedsearch</th>\n",
       "      <td>4.077757</td>\n",
       "      <td>0.253586</td>\n",
       "      <td>0.854896</td>\n",
       "      <td>0.855122</td>\n",
       "      <td>0.063783</td>\n",
       "      <td>0.189589</td>\n",
       "      <td>0.929870</td>\n",
       "      <td>0.858970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_randomizedsearch_100</th>\n",
       "      <td>63.931399</td>\n",
       "      <td>1.337555</td>\n",
       "      <td>0.919371</td>\n",
       "      <td>0.958161</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_skopt_gp_100</th>\n",
       "      <td>1.557633</td>\n",
       "      <td>0.057794</td>\n",
       "      <td>0.906729</td>\n",
       "      <td>0.910607</td>\n",
       "      <td>0.024364</td>\n",
       "      <td>0.043208</td>\n",
       "      <td>0.986249</td>\n",
       "      <td>0.914704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          fit_time  score_time  test_score  train_score  \\\n",
       "naive_bayes               0.066678    0.014363    0.781202     0.783341   \n",
       "reg_logistica             0.460645    0.018298    0.906715     0.908326   \n",
       "rf                        0.395003    0.017742    0.874312     0.995521   \n",
       "rf_bayesiano_skopt_100    7.136472    0.193855    0.910383     0.914396   \n",
       "rf_gridsearch             3.986320    0.236890    0.848783     0.849026   \n",
       "rf_randomizedsearch       4.077757    0.253586    0.854896     0.855122   \n",
       "rf_randomizedsearch_100  63.931399    1.337555    0.919371     0.958161   \n",
       "rf_skopt_gp_100           1.557633    0.057794    0.906729     0.910607   \n",
       "\n",
       "                         fit_time_idx  score_time_idx  test_score_idx  \\\n",
       "naive_bayes                  0.001043        0.010738        0.849714   \n",
       "reg_logistica                0.007205        0.013680        0.986234   \n",
       "rf                           0.006179        0.013264        0.950989   \n",
       "rf_bayesiano_skopt_100       0.111627        0.144932        0.990223   \n",
       "rf_gridsearch                0.062353        0.177107        0.923221   \n",
       "rf_randomizedsearch          0.063783        0.189589        0.929870   \n",
       "rf_randomizedsearch_100      1.000000        1.000000        1.000000   \n",
       "rf_skopt_gp_100              0.024364        0.043208        0.986249   \n",
       "\n",
       "                         train_score_idx  \n",
       "naive_bayes                     0.786865  \n",
       "reg_logistica                   0.912413  \n",
       "rf                              1.000000  \n",
       "rf_bayesiano_skopt_100          0.918510  \n",
       "rf_gridsearch                   0.852846  \n",
       "rf_randomizedsearch             0.858970  \n",
       "rf_randomizedsearch_100         0.962472  \n",
       "rf_skopt_gp_100                 0.914704  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ver_resultados()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperopt-sklearn [(link)](https://github.com/hyperopt/hyperopt-sklearn)\n",
    "\n",
    "Hyperopt-sklearn es una implementación de Hyperopt, que es la librería más famosa para optimización de hiperparámetros) pero preparado para funcionar con scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/hyperopt/hyperopt-sklearn.git\n",
      "  Cloning https://github.com/hyperopt/hyperopt-sklearn.git to /tmp/pip-hw66qmw5-build\n",
      "Collecting hyperopt (from hpsklearn==0.0.3)\n",
      "  Downloading hyperopt-0.1.tar.gz (98kB)\n",
      "\u001b[K    100% |████████████████████████████████| 102kB 1.1MB/s a 0:00:01\n",
      "\u001b[?25hCollecting nose (from hpsklearn==0.0.3)\n",
      "  Using cached nose-1.3.7-py3-none-any.whl\n",
      "Requirement already satisfied: numpy in /home/manuel/anaconda3/envs/data/lib/python3.6/site-packages (from hpsklearn==0.0.3)\n",
      "Requirement already satisfied: scikit-learn in /home/manuel/anaconda3/envs/data/lib/python3.6/site-packages (from hpsklearn==0.0.3)\n",
      "Requirement already satisfied: scipy in /home/manuel/anaconda3/envs/data/lib/python3.6/site-packages (from hpsklearn==0.0.3)\n",
      "Collecting pymongo (from hyperopt->hpsklearn==0.0.3)\n",
      "  Downloading pymongo-3.6.0-cp36-cp36m-manylinux1_x86_64.whl (378kB)\n",
      "\u001b[K    100% |████████████████████████████████| 378kB 1.7MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /home/manuel/anaconda3/envs/data/lib/python3.6/site-packages (from hyperopt->hpsklearn==0.0.3)\n",
      "Collecting networkx (from hyperopt->hpsklearn==0.0.3)\n",
      "  Downloading networkx-2.0.zip (1.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.6MB 542kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: future in /home/manuel/anaconda3/envs/data/lib/python3.6/site-packages (from hyperopt->hpsklearn==0.0.3)\n",
      "Collecting decorator>=4.1.0 (from networkx->hyperopt->hpsklearn==0.0.3)\n",
      "  Using cached decorator-4.1.2-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: hyperopt, networkx\n",
      "  Running setup.py bdist_wheel for hyperopt ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/manuel/.cache/pip/wheels/4b/0f/9d/1166e48523d3bf7478800f250b0fceae31ac6a08b8a7cca820\n",
      "  Running setup.py bdist_wheel for networkx ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/manuel/.cache/pip/wheels/27/82/23/785d5d01de2271edf929ac2761cb5dafc0dfa76a0861bfd128\n",
      "Successfully built hyperopt networkx\n",
      "Installing collected packages: nose, pymongo, decorator, networkx, hyperopt, hpsklearn\n",
      "  Found existing installation: decorator 4.0.11\n",
      "    Uninstalling decorator-4.0.11:\n",
      "      Successfully uninstalled decorator-4.0.11\n",
      "  Running setup.py install for hpsklearn ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed decorator-4.1.2 hpsklearn-0.0.3 hyperopt-0.1 networkx-2.0 nose-1.3.7 pymongo-3.6.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install git+https://github.com/hyperopt/hyperopt-sklearn.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from hpsklearn import HyperoptEstimator, random_forest\n",
    "\n",
    "optimizador_hpsklearn = HyperoptEstimator( classifier=random_forest('estimador_rf'),\n",
    "                                       seed=42, loss_fn=roc_auc_score, max_evals=100, trial_timeout=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25min 59s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "optimizador_hpsklearn.fit(censo_X_procesado, censo_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`HyperoptEstimator` nos devuelve un estimador que podemos usar como cualquiera de los de sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizador_hpsklearn.predict(censo_X_procesado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "con `best_model()` podemos ver el mejor modelo producido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ex_preprocs': (),\n",
       " 'learner': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=4, max_features=0.011994348367892704,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=3,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=1841, n_jobs=1, oob_score=False, random_state=1,\n",
       "             verbose=False, warm_start=False),\n",
       " 'preprocs': ()}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimador_hpsklearn.best_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el estimador de hyperopt-sklearn tambien puede añadir pasos de preprocesamiento automáticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelo_hpsklearn = estimador_hpsklearn.best_model()[\"learner\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resultados[\"rf_hpsklearn_10\"] = evaluar_modelo(modelo_hpsklearn, censo_X_procesado, censo_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "      <th>fit_time_idx</th>\n",
       "      <th>score_time_idx</th>\n",
       "      <th>test_score_idx</th>\n",
       "      <th>train_score_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>naive_bayes</th>\n",
       "      <td>0.066678</td>\n",
       "      <td>0.014363</td>\n",
       "      <td>0.781202</td>\n",
       "      <td>0.783341</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>0.010738</td>\n",
       "      <td>0.849714</td>\n",
       "      <td>0.786865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_logistica</th>\n",
       "      <td>0.460645</td>\n",
       "      <td>0.018298</td>\n",
       "      <td>0.906715</td>\n",
       "      <td>0.908326</td>\n",
       "      <td>0.007205</td>\n",
       "      <td>0.013680</td>\n",
       "      <td>0.986234</td>\n",
       "      <td>0.912413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.395003</td>\n",
       "      <td>0.017742</td>\n",
       "      <td>0.874312</td>\n",
       "      <td>0.995521</td>\n",
       "      <td>0.006179</td>\n",
       "      <td>0.013264</td>\n",
       "      <td>0.950989</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_bayesiano_skopt_100</th>\n",
       "      <td>7.136472</td>\n",
       "      <td>0.193855</td>\n",
       "      <td>0.910383</td>\n",
       "      <td>0.914396</td>\n",
       "      <td>0.111627</td>\n",
       "      <td>0.144932</td>\n",
       "      <td>0.990223</td>\n",
       "      <td>0.918510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_gridsearch</th>\n",
       "      <td>3.986320</td>\n",
       "      <td>0.236890</td>\n",
       "      <td>0.848783</td>\n",
       "      <td>0.849026</td>\n",
       "      <td>0.062353</td>\n",
       "      <td>0.177107</td>\n",
       "      <td>0.923221</td>\n",
       "      <td>0.852846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_hpsklearn_10</th>\n",
       "      <td>11.909622</td>\n",
       "      <td>0.755976</td>\n",
       "      <td>0.889492</td>\n",
       "      <td>0.890850</td>\n",
       "      <td>0.186288</td>\n",
       "      <td>0.565193</td>\n",
       "      <td>0.967500</td>\n",
       "      <td>0.894859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_randomizedsearch</th>\n",
       "      <td>4.077757</td>\n",
       "      <td>0.253586</td>\n",
       "      <td>0.854896</td>\n",
       "      <td>0.855122</td>\n",
       "      <td>0.063783</td>\n",
       "      <td>0.189589</td>\n",
       "      <td>0.929870</td>\n",
       "      <td>0.858970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_randomizedsearch_100</th>\n",
       "      <td>63.931399</td>\n",
       "      <td>1.337555</td>\n",
       "      <td>0.919371</td>\n",
       "      <td>0.958161</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_skopt_gp_100</th>\n",
       "      <td>1.329353</td>\n",
       "      <td>0.042163</td>\n",
       "      <td>0.905333</td>\n",
       "      <td>0.909874</td>\n",
       "      <td>0.020793</td>\n",
       "      <td>0.031522</td>\n",
       "      <td>0.984731</td>\n",
       "      <td>0.913968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          fit_time  score_time  test_score  train_score  \\\n",
       "naive_bayes               0.066678    0.014363    0.781202     0.783341   \n",
       "reg_logistica             0.460645    0.018298    0.906715     0.908326   \n",
       "rf                        0.395003    0.017742    0.874312     0.995521   \n",
       "rf_bayesiano_skopt_100    7.136472    0.193855    0.910383     0.914396   \n",
       "rf_gridsearch             3.986320    0.236890    0.848783     0.849026   \n",
       "rf_hpsklearn_10          11.909622    0.755976    0.889492     0.890850   \n",
       "rf_randomizedsearch       4.077757    0.253586    0.854896     0.855122   \n",
       "rf_randomizedsearch_100  63.931399    1.337555    0.919371     0.958161   \n",
       "rf_skopt_gp_100           1.329353    0.042163    0.905333     0.909874   \n",
       "\n",
       "                         fit_time_idx  score_time_idx  test_score_idx  \\\n",
       "naive_bayes                  0.001043        0.010738        0.849714   \n",
       "reg_logistica                0.007205        0.013680        0.986234   \n",
       "rf                           0.006179        0.013264        0.950989   \n",
       "rf_bayesiano_skopt_100       0.111627        0.144932        0.990223   \n",
       "rf_gridsearch                0.062353        0.177107        0.923221   \n",
       "rf_hpsklearn_10              0.186288        0.565193        0.967500   \n",
       "rf_randomizedsearch          0.063783        0.189589        0.929870   \n",
       "rf_randomizedsearch_100      1.000000        1.000000        1.000000   \n",
       "rf_skopt_gp_100              0.020793        0.031522        0.984731   \n",
       "\n",
       "                         train_score_idx  \n",
       "naive_bayes                     0.786865  \n",
       "reg_logistica                   0.912413  \n",
       "rf                              1.000000  \n",
       "rf_bayesiano_skopt_100          0.918510  \n",
       "rf_gridsearch                   0.852846  \n",
       "rf_hpsklearn_10                 0.894859  \n",
       "rf_randomizedsearch             0.858970  \n",
       "rf_randomizedsearch_100         0.962472  \n",
       "rf_skopt_gp_100                 0.913968  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ver_resultados()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A modo de prueba, he dejado el Optimizador de hyperopt-sklearn toda la noche corriendo. Lo bueno de este estimador es que en cualquier momento podemos parar el proceso (dandole en el notebook a `kernel->interrup` y el optimizador seguira conservando el modelo mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hpsklearn import any_classifier, any_preprocessing\n",
    "\n",
    "estimador_final = HyperoptEstimator( classifier=any_classifier(\"clf\"), \n",
    "                                    preprocessing=any_preprocessing(\"preproc\"),\n",
    "                                    seed=42, loss_fn=roc_auc_score, max_evals=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimador_final.fit(censo_X_procesado, censo_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ex_preprocs': (),\n",
       " 'learner': GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "               learning_rate=0.016925014519856875, loss='deviance',\n",
       "               max_depth=2, max_features=0.3243309842493083,\n",
       "               max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "               min_impurity_split=None, min_samples_leaf=1,\n",
       "               min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "               n_estimators=46, presort='auto', random_state=4,\n",
       "               subsample=1.0, verbose=0, warm_start=False),\n",
       " 'preprocs': (PCA(copy=True, iterated_power='auto', n_components=88, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False),)}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimador_final.best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelo_hpsklearn_final = Pipeline([\n",
    "    (\"preprocs\", estimador_final.best_model()[\"preprocs\"][0]),\n",
    "    (\"learner\", estimador_final.best_model()[\"learner\"])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resultados[\"rf_hpsklearn_final\"] = evaluar_modelo(modelo_hpsklearn_final, censo_X_procesado, censo_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "      <th>fit_time_idx</th>\n",
       "      <th>score_time_idx</th>\n",
       "      <th>test_score_idx</th>\n",
       "      <th>train_score_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>naive_bayes</th>\n",
       "      <td>0.066678</td>\n",
       "      <td>0.014363</td>\n",
       "      <td>0.781202</td>\n",
       "      <td>0.783341</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>0.010738</td>\n",
       "      <td>0.849714</td>\n",
       "      <td>0.786865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_logistica</th>\n",
       "      <td>0.460645</td>\n",
       "      <td>0.018298</td>\n",
       "      <td>0.906715</td>\n",
       "      <td>0.908326</td>\n",
       "      <td>0.007205</td>\n",
       "      <td>0.013680</td>\n",
       "      <td>0.986234</td>\n",
       "      <td>0.912413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.395003</td>\n",
       "      <td>0.017742</td>\n",
       "      <td>0.874312</td>\n",
       "      <td>0.995521</td>\n",
       "      <td>0.006179</td>\n",
       "      <td>0.013264</td>\n",
       "      <td>0.950989</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_bayesiano_skopt_100</th>\n",
       "      <td>7.136472</td>\n",
       "      <td>0.193855</td>\n",
       "      <td>0.910383</td>\n",
       "      <td>0.914396</td>\n",
       "      <td>0.111627</td>\n",
       "      <td>0.144932</td>\n",
       "      <td>0.990223</td>\n",
       "      <td>0.918510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_gridsearch</th>\n",
       "      <td>3.986320</td>\n",
       "      <td>0.236890</td>\n",
       "      <td>0.848783</td>\n",
       "      <td>0.849026</td>\n",
       "      <td>0.062353</td>\n",
       "      <td>0.177107</td>\n",
       "      <td>0.923221</td>\n",
       "      <td>0.852846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_hpsklearn_10</th>\n",
       "      <td>11.909622</td>\n",
       "      <td>0.755976</td>\n",
       "      <td>0.889492</td>\n",
       "      <td>0.890850</td>\n",
       "      <td>0.186288</td>\n",
       "      <td>0.565193</td>\n",
       "      <td>0.967500</td>\n",
       "      <td>0.894859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_hpsklearn_final</th>\n",
       "      <td>4.160803</td>\n",
       "      <td>0.031582</td>\n",
       "      <td>0.877192</td>\n",
       "      <td>0.880618</td>\n",
       "      <td>0.065082</td>\n",
       "      <td>0.023612</td>\n",
       "      <td>0.954122</td>\n",
       "      <td>0.884580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_randomizedsearch</th>\n",
       "      <td>4.077757</td>\n",
       "      <td>0.253586</td>\n",
       "      <td>0.854896</td>\n",
       "      <td>0.855122</td>\n",
       "      <td>0.063783</td>\n",
       "      <td>0.189589</td>\n",
       "      <td>0.929870</td>\n",
       "      <td>0.858970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_randomizedsearch_100</th>\n",
       "      <td>63.931399</td>\n",
       "      <td>1.337555</td>\n",
       "      <td>0.919371</td>\n",
       "      <td>0.958161</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_skopt_gp_100</th>\n",
       "      <td>1.329353</td>\n",
       "      <td>0.042163</td>\n",
       "      <td>0.905333</td>\n",
       "      <td>0.909874</td>\n",
       "      <td>0.020793</td>\n",
       "      <td>0.031522</td>\n",
       "      <td>0.984731</td>\n",
       "      <td>0.913968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          fit_time  score_time  test_score  train_score  \\\n",
       "naive_bayes               0.066678    0.014363    0.781202     0.783341   \n",
       "reg_logistica             0.460645    0.018298    0.906715     0.908326   \n",
       "rf                        0.395003    0.017742    0.874312     0.995521   \n",
       "rf_bayesiano_skopt_100    7.136472    0.193855    0.910383     0.914396   \n",
       "rf_gridsearch             3.986320    0.236890    0.848783     0.849026   \n",
       "rf_hpsklearn_10          11.909622    0.755976    0.889492     0.890850   \n",
       "rf_hpsklearn_final        4.160803    0.031582    0.877192     0.880618   \n",
       "rf_randomizedsearch       4.077757    0.253586    0.854896     0.855122   \n",
       "rf_randomizedsearch_100  63.931399    1.337555    0.919371     0.958161   \n",
       "rf_skopt_gp_100           1.329353    0.042163    0.905333     0.909874   \n",
       "\n",
       "                         fit_time_idx  score_time_idx  test_score_idx  \\\n",
       "naive_bayes                  0.001043        0.010738        0.849714   \n",
       "reg_logistica                0.007205        0.013680        0.986234   \n",
       "rf                           0.006179        0.013264        0.950989   \n",
       "rf_bayesiano_skopt_100       0.111627        0.144932        0.990223   \n",
       "rf_gridsearch                0.062353        0.177107        0.923221   \n",
       "rf_hpsklearn_10              0.186288        0.565193        0.967500   \n",
       "rf_hpsklearn_final           0.065082        0.023612        0.954122   \n",
       "rf_randomizedsearch          0.063783        0.189589        0.929870   \n",
       "rf_randomizedsearch_100      1.000000        1.000000        1.000000   \n",
       "rf_skopt_gp_100              0.020793        0.031522        0.984731   \n",
       "\n",
       "                         train_score_idx  \n",
       "naive_bayes                     0.786865  \n",
       "reg_logistica                   0.912413  \n",
       "rf                              1.000000  \n",
       "rf_bayesiano_skopt_100          0.918510  \n",
       "rf_gridsearch                   0.852846  \n",
       "rf_hpsklearn_10                 0.894859  \n",
       "rf_hpsklearn_final              0.884580  \n",
       "rf_randomizedsearch             0.858970  \n",
       "rf_randomizedsearch_100         0.962472  \n",
       "rf_skopt_gp_100                 0.913968  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ver_resultados()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
