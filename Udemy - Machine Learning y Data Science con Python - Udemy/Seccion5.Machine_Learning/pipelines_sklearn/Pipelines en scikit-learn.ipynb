{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-10-16T15:56:33+02:00\n",
      "\n",
      "CPython 3.6.1\n",
      "IPython 5.3.0\n",
      "\n",
      "compiler   : GCC 4.8.2 20140120 (Red Hat 4.8.2-15)\n",
      "system     : Linux\n",
      "release    : 4.10.0-37-generic\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 8\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datos = pd.read_csv(\"data/datos_procesamiento.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_inexistente1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col_outliers</th>\n",
       "      <th>col_outliers2</th>\n",
       "      <th>col_categorica</th>\n",
       "      <th>col_ordinal</th>\n",
       "      <th>col_texto</th>\n",
       "      <th>objetivo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2.232832</td>\n",
       "      <td>-50</td>\n",
       "      <td>0.771666</td>\n",
       "      <td>ratón</td>\n",
       "      <td>muy bien</td>\n",
       "      <td>Tenía en su casa una ama que pasaba de los cua...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.906147</td>\n",
       "      <td>-5</td>\n",
       "      <td>1.068558</td>\n",
       "      <td>elefante</td>\n",
       "      <td>regular</td>\n",
       "      <td>El resto della concluían sayo de velarte, calz...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.626750</td>\n",
       "      <td>-32</td>\n",
       "      <td>0.846396</td>\n",
       "      <td>ratón</td>\n",
       "      <td>muy mal</td>\n",
       "      <td>El resto della concluían sayo de velarte, calz...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.816738</td>\n",
       "      <td>-84</td>\n",
       "      <td>0.637381</td>\n",
       "      <td>gato</td>\n",
       "      <td>mal</td>\n",
       "      <td>Una olla de algo más vaca que carnero, salpicó...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.571131</td>\n",
       "      <td>65</td>\n",
       "      <td>4.540614</td>\n",
       "      <td>gato</td>\n",
       "      <td>bien</td>\n",
       "      <td>Tenía en su casa una ama que pasaba de los cua...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col_inexistente1  col2      col3  col_outliers  col_outliers2  \\\n",
       "0              59.0  52.0  2.232832           -50       0.771666   \n",
       "1              31.0  74.0  0.906147            -5       1.068558   \n",
       "2              81.0  28.0  0.626750           -32       0.846396   \n",
       "3              34.0  16.0  0.816738           -84       0.637381   \n",
       "4              32.0  28.0  0.571131            65       4.540614   \n",
       "\n",
       "  col_categorica col_ordinal  \\\n",
       "0          ratón    muy bien   \n",
       "1       elefante     regular   \n",
       "2          ratón     muy mal   \n",
       "3           gato         mal   \n",
       "4           gato        bien   \n",
       "\n",
       "                                           col_texto  objetivo  \n",
       "0  Tenía en su casa una ama que pasaba de los cua...         1  \n",
       "1  El resto della concluían sayo de velarte, calz...         0  \n",
       "2  El resto della concluían sayo de velarte, calz...         0  \n",
       "3  Una olla de algo más vaca que carnero, salpicó...         0  \n",
       "4  Tenía en su casa una ama que pasaba de los cua...         0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing, feature_extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vimos en un apartado anterior, en este ejemplo vamos a modificar cada variable en función de su tipo. Al conjunto de pasos que siguen los datos se le llama comúnmente **Pipelines** (literalmente, sistemas de tuberias)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh0AAAKBCAYAAADzxBnfAAAgAElEQVR4nOzdXYhbV773+XWT2uEJ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\nDgBgCNEBAAwhOgCAIX4AMg3cQT9EiIEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(\"../../media/pipeline.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INCISO**\n",
    "\n",
    "vamos a modificar dos transformadores de scikitlearn para que sean compatibles con pipelines. Este paso es necesario en la version actual de scikit-learn, pero seguramente será arreglado en el futuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BinarizadorCategorico(preprocessing.LabelBinarizer):\n",
    "    def fit(self, X, y=None):\n",
    "        super(BinarizadorCategorico, self).fit(X)\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        return super(BinarizadorCategorico, self).transform(X)\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return super(BinarizadorCategorico, self).fit(X).transform(X)\n",
    "    \n",
    "    \n",
    "class CodificadorCategorico(preprocessing.LabelEncoder):\n",
    "    def fit(self, X, y=None):\n",
    "        super(CodificadorCategorico, self).fit(X)\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        return super(CodificadorCategorico, self).transform(X)\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return super(CodificadorCategorico, self).fit(X).transform(X)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar vamos a definir los transformadores de forma similar a como hicimos la última vez, solo que en vez de usar `OneHotEncoder` vamos a usar nuestra version de sklearn `LabelBinarizer` que hace la codificación one hot directamente sobre una variable categórica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "col_numericas =  ['col_inexistente1', 'col2', 'col3', 'col_outliers', 'col_outliers2']\n",
    "col_categorica = ['col_categorica']\n",
    "col_texto = ['col_texto']\n",
    "col_ordinal = ['col_ordinal']\n",
    "\n",
    "imputador = preprocessing.Imputer()\n",
    "escalador = preprocessing.StandardScaler()\n",
    "\n",
    "transformador_ordinal = CodificadorCategorico()\n",
    "transformador_categorico = BinarizadorCategorico()\n",
    "\n",
    "transformador_texto = feature_extraction.text.TfidfVectorizer()\n",
    "\n",
    "estimador = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que con el Binarizador transformamos como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_categorica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ratón</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>elefante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ratón</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>perro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>perro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>perro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>elefante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>elefante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>perro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>elefante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ratón</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ratón</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>elefante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ratón</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ratón</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>elefante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ratón</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ratón</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ratón</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>gato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>gato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ratón</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>gato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>elefante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>gato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>elefante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>ratón</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>gato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>elefante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>perro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>perro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>elefante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>ratón</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>perro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>elefante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>ratón</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>gato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>perro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>ratón</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>gato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>gato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>ratón</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>ratón</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>gato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>perro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>perro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>perro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>elefante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>gato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>ratón</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>ratón</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>elefante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>ratón</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>elefante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>elefante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>elefante</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    col_categorica\n",
       "0            ratón\n",
       "1         elefante\n",
       "2            ratón\n",
       "3             gato\n",
       "4             gato\n",
       "5            perro\n",
       "6            perro\n",
       "7            perro\n",
       "8         elefante\n",
       "9         elefante\n",
       "10           perro\n",
       "11        elefante\n",
       "12            gato\n",
       "13           ratón\n",
       "14            gato\n",
       "15           ratón\n",
       "16        elefante\n",
       "17           ratón\n",
       "18           ratón\n",
       "19        elefante\n",
       "20           ratón\n",
       "21           ratón\n",
       "22           ratón\n",
       "23            gato\n",
       "24            gato\n",
       "25           ratón\n",
       "26            gato\n",
       "27        elefante\n",
       "28            gato\n",
       "29        elefante\n",
       "..             ...\n",
       "970          ratón\n",
       "971           gato\n",
       "972       elefante\n",
       "973          perro\n",
       "974          perro\n",
       "975       elefante\n",
       "976          ratón\n",
       "977          perro\n",
       "978       elefante\n",
       "979          ratón\n",
       "980           gato\n",
       "981          perro\n",
       "982          ratón\n",
       "983           gato\n",
       "984           gato\n",
       "985          ratón\n",
       "986          ratón\n",
       "987           gato\n",
       "988          perro\n",
       "989          perro\n",
       "990          perro\n",
       "991       elefante\n",
       "992           gato\n",
       "993          ratón\n",
       "994          ratón\n",
       "995       elefante\n",
       "996          ratón\n",
       "997       elefante\n",
       "998       elefante\n",
       "999       elefante\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos[col_categorica]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       ..., \n",
       "       [1, 0, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [1, 0, 0, 0]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformador_categorico.fit_transform(datos[col_categorica])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que es mucho más sencillo que cómo lo hicimos la vez anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manuel/anaconda3/envs/data/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/manuel/anaconda3/envs/data/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.],\n",
       "       ..., \n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing.OneHotEncoder().fit_transform(\n",
    "    transformador_ordinal.fit_transform(datos[col_categorica]).reshape(1000,1)\n",
    ").toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un pipeline de sklearn se define como una secuencia de pasos. Cada paso se define con una tupla de forma `[nombre del paso, transformador]`\n",
    "\n",
    "Por ejemplo, si queremos crear un pipeline que procese las variables numéricas, primero imputándolas y después estandarizandolas, podriamos crear un pipeline como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformador_numerico = Pipeline(\n",
    "     [('imputador', imputador), ('escalador', escalador)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('imputador', Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)), ('escalador', StandardScaler(copy=True, with_mean=True, with_std=True))])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformador_numerico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tenemos definidos los pasos que queremos aplicar a cada variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.39921733,  0.08280686,  0.44281884, -0.69460006, -0.03836537],\n",
       "       [-0.65360504,  0.86133291, -0.32339035, -0.11846597, -0.03827803],\n",
       "       [ 1.22643491, -0.76649428, -0.4847522 , -0.46414642, -0.03834338],\n",
       "       ..., \n",
       "       [-1.10481463,  0.11819441, -0.42094381,  0.88016644, -0.03819664],\n",
       "       [ 1.48964051,  1.56908386, -0.4077454 ,  0.81615154, -0.03818958],\n",
       "       [ 1.7152453 ,  0.22435705, -0.13638793,  0.72653069, -0.03831468]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformador_numerico.fit_transform(datos[col_numericas])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero seguimos teniendo el mismo problema de siempre, como podemos aplicar determinados transformadores a determinadas variables?\n",
    "\n",
    "Bien, para los casos en los que tenemos un dataframe de Pandas, una opcion es crear un transformador customizado que simplemente selecciones columnas de un dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En `scikit-learn` podemos crear nuestros propios transformadores creando una clase que herede de `TransformerMixin` y que tenga el mètodo `transform`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class TransformadorBase(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear dos transformadores, un `DenseTransformer` que convierte una matriz `sparse` en un array (tomado de [mlxtend](http://rasbt.github.io/mlxtend/), y `ColumnExtractor` que devuelve una selección de columnas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "\n",
    "# http://rasbt.github.io/mlxtend/\n",
    "class DenseTransformer(BaseEstimator):\n",
    "    def __init__(self, return_copy=True):\n",
    "        self.return_copy = return_copy\n",
    "        self.is_fitted = False\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        if issparse(X):\n",
    "            return X.toarray()\n",
    "        elif self.return_copy:\n",
    "            return X.copy()\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X=X, y=y)\n",
    "\n",
    "class ColumnExtractor(TransformerMixin):\n",
    "\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        \n",
    "    def transform(self, X, **transform_params):\n",
    "        return X[self.columns].as_matrix()\n",
    "        \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ejemplo si creamos un ColumnExtractor pasandole las columnas numéricas tenemos un transformador que podemos usar en un pipeline y que simplemente selecciona un subgrupo de columnas (devolviendolas como matriz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cext = ColumnExtractor(columns=col_numericas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 59.        ,  52.        ,   2.23283208, -50.        ,\n",
       "          0.77166646],\n",
       "       [ 31.        ,  74.        ,   0.90614714,  -5.        ,\n",
       "          1.06855838],\n",
       "       [ 81.        ,  28.        ,   0.62675042, -32.        ,\n",
       "          0.84639576],\n",
       "       ..., \n",
       "       [ 19.        ,  53.        ,   0.73723413,  73.        ,\n",
       "          1.34525201],\n",
       "       [ 88.        ,  94.        ,   0.76008706,  68.        ,   1.3692463 ],\n",
       "       [ 94.        ,  56.        ,   1.2299403 ,  61.        ,\n",
       "          0.94395714]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cext.fit_transform(datos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos ahora los pipelines para cada tipo de variable. En algunos casos he añadido pasos adicionales por dos motivos. El primero, que determinados elementos de sklearn esperan datos ligeramente distintos. En segundo lugar, para conseguir que la salida de cada pipeline tenga la misma forma (un array de arrays)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.39921733,  0.08280686,  0.44281884, -0.69460006, -0.03836537],\n",
       "       [-0.65360504,  0.86133291, -0.32339035, -0.11846597, -0.03827803],\n",
       "       [ 1.22643491, -0.76649428, -0.4847522 , -0.46414642, -0.03834338],\n",
       "       [-0.54080264, -1.19114485, -0.37502756, -1.12990136, -0.03840487],\n",
       "       [-0.61600424, -0.76649428, -0.51687443,  0.77774261, -0.03725668]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_numerico = Pipeline([\n",
    "    ['selector_numerico', ColumnExtractor(columns=col_numericas)],\n",
    "    ['transformador_numerico', transformador_numerico]\n",
    "])\n",
    "\n",
    "pipeline_numerico.fit_transform(datos)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.20474512,  0.        ,  0.        ,  0.        ,  0.20474512,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.20474512,  0.        ,  0.        ,  0.20474512,\n",
       "         0.        ,  0.        ,  0.        ,  0.20474512,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.20474512,  0.        ,  0.        ,  0.14641557,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.12243162,\n",
       "         0.12073233,  0.        ,  0.20474512,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.10065821,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.20474512,  0.        ,  0.14641557,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.20474512,  0.        ,  0.        ,\n",
       "         0.        ,  0.12073233,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.20474512,  0.        ,  0.20474512,  0.        ,  0.20474512,\n",
       "         0.        ,  0.        ,  0.30944223,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.15034558,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.20474512,  0.12716589,  0.        ,  0.        ,  0.15225823,\n",
       "         0.        ,  0.20474512,  0.        ,  0.12073233,  0.31898902,\n",
       "         0.        ,  0.20474512,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.18184158,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.27509712,  0.18184158,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.32927279,  0.        ,\n",
       "         0.        ,  0.18184158,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.18184158,  0.        ,  0.11013419,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.18184158,\n",
       "         0.        ,  0.        ,  0.        ,  0.18184158,  0.18184158,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.18184158,  0.        ,\n",
       "         0.        ,  0.        ,  0.14220382,  0.        ,  0.        ,\n",
       "         0.        ,  0.36368315,  0.06585456,  0.        ,  0.        ,\n",
       "         0.        ,  0.18184158,  0.        ,  0.        ,  0.14220382,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.18184158,  0.18184158,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.18184158,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.18184158,  0.13581291,  0.        ,  0.18184158,  0.        ,\n",
       "         0.        ,  0.11439294,  0.18184158,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.18184158,  0.18184158,  0.18184158,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.18184158,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.27509712,  0.18184158,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.32927279,  0.        ,\n",
       "         0.        ,  0.18184158,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.18184158,  0.        ,  0.11013419,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.18184158,\n",
       "         0.        ,  0.        ,  0.        ,  0.18184158,  0.18184158,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.18184158,  0.        ,\n",
       "         0.        ,  0.        ,  0.14220382,  0.        ,  0.        ,\n",
       "         0.        ,  0.36368315,  0.06585456,  0.        ,  0.        ,\n",
       "         0.        ,  0.18184158,  0.        ,  0.        ,  0.14220382,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.18184158,  0.18184158,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.18184158,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.18184158,  0.13581291,  0.        ,  0.18184158,  0.        ,\n",
       "         0.        ,  0.11439294,  0.18184158,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.18184158,  0.18184158,  0.18184158,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.19427241,  0.        ,  0.19427241,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.19427241,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.19427241,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.19427241,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.19783944,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.19427241,\n",
       "         0.19427241,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.19427241,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.28480462,  0.19427241,  0.        ,\n",
       "         0.        ,  0.        ,  0.19783944,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.28480462,\n",
       "         0.        ,  0.        ,  0.19427241,  0.        ,  0.        ,\n",
       "         0.19427241,  0.19427241,  0.        ,  0.        ,  0.19427241,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.09291646,  0.19427241,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.19427241,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.11455261,  0.        ,  0.19427241,  0.        ,\n",
       "         0.        ,  0.        ,  0.19427241,  0.        ,  0.14367463,\n",
       "         0.19427241,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.19427241,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.20474512,  0.        ,  0.        ,  0.        ,  0.20474512,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.20474512,  0.        ,  0.        ,  0.20474512,\n",
       "         0.        ,  0.        ,  0.        ,  0.20474512,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.20474512,  0.        ,  0.        ,  0.14641557,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.12243162,\n",
       "         0.12073233,  0.        ,  0.20474512,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.10065821,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.20474512,  0.        ,  0.14641557,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.20474512,  0.        ,  0.        ,\n",
       "         0.        ,  0.12073233,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.20474512,  0.        ,  0.20474512,  0.        ,  0.20474512,\n",
       "         0.        ,  0.        ,  0.30944223,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.15034558,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.20474512,  0.12716589,  0.        ,  0.        ,  0.15225823,\n",
       "         0.        ,  0.20474512,  0.        ,  0.12073233,  0.31898902,\n",
       "         0.        ,  0.20474512,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_texto = Pipeline([\n",
    "        ['selector_texto', ColumnExtractor(columns=col_texto)],\n",
    "        ['transformador_dim', preprocessing.FunctionTransformer(lambda x: x[:,0], validate=False)],\n",
    "        ['transformador_texto', transformador_texto],\n",
    "        ['texto_array', DenseTransformer()]\n",
    "    ])\n",
    "\n",
    "pipeline_texto.fit_transform(datos)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_categorico = Pipeline([\n",
    "    ['selector_categorica', ColumnExtractor(columns=col_categorica)],\n",
    "    ['transformador_categorico', transformador_categorico]\n",
    "])\n",
    "\n",
    "pipeline_categorico.fit_transform(datos)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso del pipeline ordinal hay que manipular las dimensiones de los arrays dado que trabaja con un vector de dimension 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [4],\n",
       "       [3],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_ordinal = Pipeline([\n",
    "    ['selector_ordinal', ColumnExtractor(columns=col_ordinal)],\n",
    "    ['transformador_dim1', preprocessing.FunctionTransformer(lambda x: x[:,0], validate=False)],\n",
    "    ['transformador_ordinal', transformador_ordinal],\n",
    "    ['transformador_dim2', preprocessing.FunctionTransformer(lambda x: np.vstack(x[:]), validate=False)],\n",
    "])\n",
    "\n",
    "\n",
    "pipeline_ordinal.fit_transform(datos)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya tenemos una manera de, dado un conjunto de datos, separarlos y aplicar distintas transformaciones a cada variable. Nos falta una manera de, una vez se han transformado, reunirlas de nuevo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ello podemos usar `FeatureUnion`, que simplemente toma un conjunto de pasos de un pipeline y los une."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline_procesado = FeatureUnion([\n",
    "    ('variables_numericas', pipeline_numerico),\n",
    "    ('variables_ordinales', pipeline_ordinal),\n",
    "    ('variables_texto', pipeline_texto),\n",
    "    ('variables_categoricas', pipeline_categorico),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('variables_numericas', Pipeline(memory=None,\n",
       "     steps=[('selector_numerico', <__main__.ColumnExtractor object at 0x7f389c7fc860>), ['transformador_numerico', Pipeline(memory=None,\n",
       "     steps=[('imputador', Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose...transformador_categorico', BinarizadorCategorico(neg_label=0, pos_label=1, sparse_output=False)]]))],\n",
       "       transformer_weights=None)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_procesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.39921733,  0.08280686,  0.44281884, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-0.65360504,  0.86133291, -0.32339035, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.22643491, -0.76649428, -0.4847522 , ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       ..., \n",
       "       [-1.10481463,  0.11819441, -0.42094381, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.48964051,  1.56908386, -0.4077454 , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.7152453 ,  0.22435705, -0.13638793, ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_procesado.fit_transform(datos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, necesitamos añadir un estimador al final para predecir en base a los datos transformados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline_estimador = Pipeline([\n",
    "    ('procesador', pipeline_procesado),\n",
    "    ('estimador', estimador)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('procesador', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('variables_numericas', Pipeline(memory=None,\n",
       "     steps=[('selector_numerico', <__main__.ColumnExtractor object at 0x7f389c7fc860>), ['transformador_numerico', Pipeline(memory=None,\n",
       "     steps=[('imputador', Imputer(axis=0, copy=...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_estimador.fit(datos, datos.objetivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_estimador.predict(datos)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El beneficio de los pipelines, no solo es tener codigo mas legible y poder gestionar de forma ordenada todo el ciclo de vida del modelado, sino que los pipelines tienen todos los beneficios de los objetos de scikitlearn, por ejemplo, podemos usar validacion cruzada directamente con el pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.53326733,  0.48934893,  0.52035204,  0.49464946,  0.47535354])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipeline_estimador, X=datos.drop('objetivo', axis=1), y=datos.objetivo, scoring='roc_auc', cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La forma de usar `Pipeline` junto con `FeatureUnion` es la forma mas comun de usar pipelines. Sin embargo, existe una forma mas simplificada en la que no le asignamos nombres a los elementos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline, make_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline_simple = make_pipeline(\n",
    "    make_union(\n",
    "       pipeline_numerico,\n",
    "       pipeline_ordinal,\n",
    "       pipeline_texto,\n",
    "       pipeline_categorico,\n",
    "    ),\n",
    "    estimador\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('featureunion', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('pipeline-1', Pipeline(memory=None,\n",
       "     steps=[('selector_numerico', <__main__.ColumnExtractor object at 0x7f389c7fc860>), ['transformador_numerico', Pipeline(memory=None,\n",
       "     steps=[('imputador', Imputer(axis=0, copy=True, m...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.53326733,  0.48934893,  0.52035204,  0.49464946,  0.47535354])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipeline_simple, X=datos.drop('objetivo', axis=1), y=datos.objetivo, scoring='roc_auc', cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para aquellos casos en los que los datos que tengamos nos permitan trabajar con DataFrames de pandas (datasets tabulares) podemos usar [sklearn-pandas](https://github.com/pandas-dev/sklearn-pandas) que hace el uso de pipelines de scikit-learn bastante mas sencillo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn-pandas in /home/manuel/anaconda3/envs/data/lib/python3.6/site-packages\n",
      "Requirement already satisfied: scipy>=0.14 in /home/manuel/anaconda3/envs/data/lib/python3.6/site-packages (from sklearn-pandas)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /home/manuel/anaconda3/envs/data/lib/python3.6/site-packages (from sklearn-pandas)\n",
      "Requirement already satisfied: scikit-learn>=0.15.0 in /home/manuel/anaconda3/envs/data/lib/python3.6/site-packages (from sklearn-pandas)\n",
      "Requirement already satisfied: pandas>=0.11.0 in /home/manuel/anaconda3/envs/data/lib/python3.6/site-packages (from sklearn-pandas)\n",
      "Requirement already satisfied: python-dateutil>=2 in /home/manuel/anaconda3/envs/data/lib/python3.6/site-packages (from pandas>=0.11.0->sklearn-pandas)\n",
      "Requirement already satisfied: pytz>=2011k in /home/manuel/anaconda3/envs/data/lib/python3.6/site-packages (from pandas>=0.11.0->sklearn-pandas)\n",
      "Requirement already satisfied: six>=1.5 in /home/manuel/anaconda3/envs/data/lib/python3.6/site-packages (from python-dateutil>=2->pandas>=0.11.0->sklearn-pandas)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn_pandas import DataFrameMapper, cross_val_score as sklearn_pandas_cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_inexistente1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col_outliers</th>\n",
       "      <th>col_outliers2</th>\n",
       "      <th>col_categorica</th>\n",
       "      <th>col_ordinal</th>\n",
       "      <th>col_texto</th>\n",
       "      <th>objetivo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2.232832</td>\n",
       "      <td>-50</td>\n",
       "      <td>0.771666</td>\n",
       "      <td>ratón</td>\n",
       "      <td>muy bien</td>\n",
       "      <td>Tenía en su casa una ama que pasaba de los cua...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.906147</td>\n",
       "      <td>-5</td>\n",
       "      <td>1.068558</td>\n",
       "      <td>elefante</td>\n",
       "      <td>regular</td>\n",
       "      <td>El resto della concluían sayo de velarte, calz...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.626750</td>\n",
       "      <td>-32</td>\n",
       "      <td>0.846396</td>\n",
       "      <td>ratón</td>\n",
       "      <td>muy mal</td>\n",
       "      <td>El resto della concluían sayo de velarte, calz...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.816738</td>\n",
       "      <td>-84</td>\n",
       "      <td>0.637381</td>\n",
       "      <td>gato</td>\n",
       "      <td>mal</td>\n",
       "      <td>Una olla de algo más vaca que carnero, salpicó...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.571131</td>\n",
       "      <td>65</td>\n",
       "      <td>4.540614</td>\n",
       "      <td>gato</td>\n",
       "      <td>bien</td>\n",
       "      <td>Tenía en su casa una ama que pasaba de los cua...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col_inexistente1  col2      col3  col_outliers  col_outliers2  \\\n",
       "0              59.0  52.0  2.232832           -50       0.771666   \n",
       "1              31.0  74.0  0.906147            -5       1.068558   \n",
       "2              81.0  28.0  0.626750           -32       0.846396   \n",
       "3              34.0  16.0  0.816738           -84       0.637381   \n",
       "4              32.0  28.0  0.571131            65       4.540614   \n",
       "\n",
       "  col_categorica col_ordinal  \\\n",
       "0          ratón    muy bien   \n",
       "1       elefante     regular   \n",
       "2          ratón     muy mal   \n",
       "3           gato         mal   \n",
       "4           gato        bien   \n",
       "\n",
       "                                           col_texto  objetivo  \n",
       "0  Tenía en su casa una ama que pasaba de los cua...         1  \n",
       "1  El resto della concluían sayo de velarte, calz...         0  \n",
       "2  El resto della concluían sayo de velarte, calz...         0  \n",
       "3  Una olla de algo más vaca que carnero, salpicó...         0  \n",
       "4  Tenía en su casa una ama que pasaba de los cua...         0  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapeador = DataFrameMapper([\n",
    "     (['col_inexistente1'], transformador_numerico),\n",
    "     (['col2'], transformador_numerico),\n",
    "     ([\"col3\"], transformador_numerico),\n",
    "    ([\"col_outliers\"], transformador_numerico),\n",
    "    ([\"col_outliers2\"], transformador_numerico),\n",
    "    (\"col_categorica\", transformador_categorico),\n",
    "    (\"col_ordinal\", transformador_ordinal),\n",
    "    (\"col_texto\", transformador_texto)\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02123668, -0.02329583, -0.03793554, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.02947328, -0.01682422, -0.03832581, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.01476508, -0.03035577, -0.038408  , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ..., \n",
       "       [-0.03300325, -0.02300167, -0.0383755 , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.01270593, -0.01094094, -0.03836877, ...,  0.        ,\n",
       "         0.        ,  0.19788701],\n",
       "       [-0.01094094, -0.02211918, -0.03823056, ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapeador.fit_transform(datos.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['col_inexistente1'], Pipeline(memory=None,\n",
       "       steps=[('imputador', Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)), ('escalador', StandardScaler(copy=True, with_mean=True, with_std=True))])),\n",
       " (['col2'], Pipeline(memory=None,\n",
       "       steps=[('imputador', Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)), ('escalador', StandardScaler(copy=True, with_mean=True, with_std=True))])),\n",
       " (['col3'], Pipeline(memory=None,\n",
       "       steps=[('imputador', Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)), ('escalador', StandardScaler(copy=True, with_mean=True, with_std=True))])),\n",
       " (['col_outliers'], Pipeline(memory=None,\n",
       "       steps=[('imputador', Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)), ('escalador', StandardScaler(copy=True, with_mean=True, with_std=True))])),\n",
       " (['col_outliers2'], Pipeline(memory=None,\n",
       "       steps=[('imputador', Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)), ('escalador', StandardScaler(copy=True, with_mean=True, with_std=True))])),\n",
       " ('col_categorica',\n",
       "  BinarizadorCategorico(neg_label=0, pos_label=1, sparse_output=False)),\n",
       " ('col_ordinal', CodificadorCategorico()),\n",
       " ('col_texto',\n",
       "  TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "          dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "          lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "          ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "          stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "          token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "          vocabulary=None))]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapeador.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['col_inexistente1',\n",
       " 'col2',\n",
       " 'col3',\n",
       " 'col_outliers',\n",
       " 'col_outliers2',\n",
       " 'col_categorica_elefante',\n",
       " 'col_categorica_gato',\n",
       " 'col_categorica_perro',\n",
       " 'col_categorica_ratón',\n",
       " 'col_ordinal',\n",
       " 'col_texto_acordarme',\n",
       " 'col_texto_adarga',\n",
       " 'col_texto_algo',\n",
       " 'col_texto_alguna',\n",
       " 'col_texto_algún',\n",
       " 'col_texto_ama',\n",
       " 'col_texto_amigo',\n",
       " 'col_texto_antigua',\n",
       " 'col_texto_astillero',\n",
       " 'col_texto_así',\n",
       " 'col_texto_aunque',\n",
       " 'col_texto_autores',\n",
       " 'col_texto_añadidura',\n",
       " 'col_texto_años',\n",
       " 'col_texto_basta',\n",
       " 'col_texto_calzas',\n",
       " 'col_texto_campo',\n",
       " 'col_texto_carnero',\n",
       " 'col_texto_carnes',\n",
       " 'col_texto_casa',\n",
       " 'col_texto_caso',\n",
       " 'col_texto_caza',\n",
       " 'col_texto_cincuenta',\n",
       " 'col_texto_como',\n",
       " 'col_texto_complexión',\n",
       " 'col_texto_con',\n",
       " 'col_texto_concluían',\n",
       " 'col_texto_conjeturas',\n",
       " 'col_texto_consumían',\n",
       " 'col_texto_corredor',\n",
       " 'col_texto_cuarenta',\n",
       " 'col_texto_cuento',\n",
       " 'col_texto_cuyo',\n",
       " 'col_texto_de',\n",
       " 'col_texto_decir',\n",
       " 'col_texto_deja',\n",
       " 'col_texto_della',\n",
       " 'col_texto_deste',\n",
       " 'col_texto_diferencia',\n",
       " 'col_texto_domingos',\n",
       " 'col_texto_duelos',\n",
       " 'col_texto_dél',\n",
       " 'col_texto_días',\n",
       " 'col_texto_edad',\n",
       " 'col_texto_el',\n",
       " 'col_texto_en',\n",
       " 'col_texto_enjuto',\n",
       " 'col_texto_ensillaba',\n",
       " 'col_texto_entender',\n",
       " 'col_texto_entre',\n",
       " 'col_texto_era',\n",
       " 'col_texto_escriben',\n",
       " 'col_texto_esto',\n",
       " 'col_texto_fiestas',\n",
       " 'col_texto_fino',\n",
       " 'col_texto_flaco',\n",
       " 'col_texto_frisaba',\n",
       " 'col_texto_galgo',\n",
       " 'col_texto_gran',\n",
       " 'col_texto_ha',\n",
       " 'col_texto_hacienda',\n",
       " 'col_texto_hay',\n",
       " 'col_texto_hidalgo',\n",
       " 'col_texto_honraba',\n",
       " 'col_texto_importa',\n",
       " 'col_texto_la',\n",
       " 'col_texto_lanza',\n",
       " 'col_texto_las',\n",
       " 'col_texto_lentejas',\n",
       " 'col_texto_llama',\n",
       " 'col_texto_llegaba',\n",
       " 'col_texto_lo',\n",
       " 'col_texto_los',\n",
       " 'col_texto_lugar',\n",
       " 'col_texto_madrugador',\n",
       " 'col_texto_mancha',\n",
       " 'col_texto_mismo',\n",
       " 'col_texto_mozo',\n",
       " 'col_texto_mucho',\n",
       " 'col_texto_más',\n",
       " 'col_texto_narración',\n",
       " 'col_texto_no',\n",
       " 'col_texto_noches',\n",
       " 'col_texto_nombre',\n",
       " 'col_texto_nuestro',\n",
       " 'col_texto_olla',\n",
       " 'col_texto_palomino',\n",
       " 'col_texto_pantuflos',\n",
       " 'col_texto_para',\n",
       " 'col_texto_partes',\n",
       " 'col_texto_pasaba',\n",
       " 'col_texto_pero',\n",
       " 'col_texto_plaza',\n",
       " 'col_texto_poco',\n",
       " 'col_texto_podadera',\n",
       " 'col_texto_por',\n",
       " 'col_texto_punto',\n",
       " 'col_texto_que',\n",
       " 'col_texto_quebrantos',\n",
       " 'col_texto_quesada',\n",
       " 'col_texto_quieren',\n",
       " 'col_texto_quiero',\n",
       " 'col_texto_quijada',\n",
       " 'col_texto_quijana',\n",
       " 'col_texto_recia',\n",
       " 'col_texto_resto',\n",
       " 'col_texto_rocín',\n",
       " 'col_texto_rostro',\n",
       " 'col_texto_salga',\n",
       " 'col_texto_salpicón',\n",
       " 'col_texto_sayo',\n",
       " 'col_texto_se',\n",
       " 'col_texto_seco',\n",
       " 'col_texto_semana',\n",
       " 'col_texto_sobrenombre',\n",
       " 'col_texto_sobrina',\n",
       " 'col_texto_su',\n",
       " 'col_texto_sus',\n",
       " 'col_texto_sábados',\n",
       " 'col_texto_tenía',\n",
       " 'col_texto_tiempo',\n",
       " 'col_texto_tomaba',\n",
       " 'col_texto_tres',\n",
       " 'col_texto_un',\n",
       " 'col_texto_una',\n",
       " 'col_texto_vaca',\n",
       " 'col_texto_veinte',\n",
       " 'col_texto_velarte',\n",
       " 'col_texto_vellori',\n",
       " 'col_texto_velludo',\n",
       " 'col_texto_verdad',\n",
       " 'col_texto_verosímiles',\n",
       " 'col_texto_viernes',\n",
       " 'col_texto_vivía']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapeador.transformed_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline_estimador_pandas_sklearn = Pipeline([\n",
    "    ('procesador', mapeador),\n",
    "    ('estimador', estimador)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.53326733,  0.48934893,  0.52035204,  0.49464946,  0.47535354])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_pandas_cross_val_score(pipeline_estimador_pandas_sklearn, X=datos.drop('objetivo', axis=1).copy(),\n",
    "                               y=datos.objetivo, scoring='roc_auc', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
